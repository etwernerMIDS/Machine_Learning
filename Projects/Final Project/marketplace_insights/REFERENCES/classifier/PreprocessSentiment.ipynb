{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df = pd.read_csv('../data/Reviews.csv')\n",
    "df['Text'] = df['Text'] + ' ' + df['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unused columns\n",
    "del df['Id']\n",
    "del df['ProfileName']\n",
    "del df['Summary']\n",
    "del df['HelpfulnessNumerator']\n",
    "del df['HelpfulnessDenominator']\n",
    "del df['Time']\n",
    "del df['ProductId']\n",
    "del df['UserId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Score'] <= 3, 'ReviewSentiment'] = 0\n",
    "df.loc[df['Score'] > 3, 'ReviewSentiment'] = 1\n",
    "\n",
    "df['ReviewSentiment'] = df['ReviewSentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert na to \"\"\n",
    "df['Text'].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103725\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "\n",
    "def preprocess(s):\n",
    "    # Remove html tags\n",
    "    s = re.sub('<\\S+>', '', s)\n",
    "    # Replace urls with token\n",
    "    s = re.sub(r'http:\\S+', 'url', s)\n",
    "    s = re.sub(r'https:\\S+', 'url', s)\n",
    "    \n",
    "    s = s.lower()\n",
    "    # Remove any other special characters\n",
    "    s = re.sub(r'[^a-z ]', ' ', s)\n",
    "    \n",
    "    words = s.split()\n",
    "    result = []\n",
    "    \n",
    "    # Remove stop words and lemmatize the words\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        result.append(word)\n",
    "        vocab.add(word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "df['Text'] = df['Text'].apply(preprocess)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>ReviewSentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanut pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  ReviewSentiment\n",
       "0  bought several vitality canned dog food produc...                1\n",
       "1  product arrived labeled jumbo salted peanut pe...                0\n",
       "2  confection around century light pillowy citrus...                1\n",
       "3  looking secret ingredient robitussin believe f...                0\n",
       "4  great taffy great price wide assortment yummy ...                1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['Score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del vocab"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
