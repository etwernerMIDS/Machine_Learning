{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t55qCf3Fsxa"
   },
   "source": [
    "# Project 2: Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9-9G8z4Fsxd"
   },
   "source": [
    "In this project, you'll work with text data from newsgroup postings on a variety of topics. You'll train classifiers to distinguish between the topics based on the text of the posts. Whereas with digit classification, the input is relatively dense: a 28x28 matrix of pixels, many of which are non-zero, here we'll represent each document with a \"bag-of-words\" model. As you'll see, this makes the feature representation quite sparse -- only a few words of the total vocabulary are active in any given document. The bag-of-words assumption here is that the label depends only on the words; their order is not important.\n",
    "\n",
    "The SK-learn documentation on feature extraction will prove useful:\n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but please prepare your own write-up and write your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUYW83LqFsxd"
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ALNjGgCFsxg"
   },
   "source": [
    "Load the data, stripping out metadata so that we learn classifiers that only use textual features. By default, newsgroups data is split into train and test sets. We further split the test so we have a dev set. Note that we specify 4 categories to use for this project. If you remove the categories argument from the fetch function, you'll get all 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecYpcoxaFsxh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label shape: (2034,)\n",
      "test label shape: (677,)\n",
      "dev label shape: (676,)\n",
      "labels names: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "num_test = int(len(newsgroups_test.target) / 2)\n",
    "test_data, test_labels = newsgroups_test.data[num_test:], newsgroups_test.target[num_test:]\n",
    "dev_data, dev_labels = newsgroups_test.data[:num_test], newsgroups_test.target[:num_test]\n",
    "train_data, train_labels = newsgroups_train.data, newsgroups_train.target\n",
    "\n",
    "print('training label shape:', train_labels.shape)\n",
    "print('test label shape:', test_labels.shape)\n",
    "print('dev label shape:', dev_labels.shape)\n",
    "print('labels names:', newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHTnOke6Fsxk"
   },
   "source": [
    "### Part 1:\n",
    "\n",
    "For each of the first 5 training examples, print the text of the message along with the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8zhA06xFsxl"
   },
   "outputs": [],
   "source": [
    "def P1(num_examples=5):\n",
    "    \"\"\" P1 - Prints the text of the message along with its label, for the first <input> examples. \n",
    "    # param num_examples: integer that indicates the number of examples to print\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #iterate for the given input value\n",
    "    for i in range(0,num_examples):\n",
    "        #get the message and the label\n",
    "        message = train_data[i]\n",
    "        label = train_labels[i]\n",
    "        \n",
    "        #map the label to its category\n",
    "        if label == 0:\n",
    "            lab_type = 'alt.atheism'\n",
    "        elif label == 1:\n",
    "            lab_type = 'comp.graphics'\n",
    "        elif label == 2:\n",
    "            lab_type = 'sci.space'\n",
    "        else:\n",
    "            lab_type = 'talk.religion.misc'\n",
    "        \n",
    "        #print the messages and their labels\n",
    "        print('Message ', i+1, ': ', message )\n",
    "        print('\\nLabel: ', label, ' & Label Category: ', lab_type)\n",
    "        print('_________________________________________________________________________________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message  1 :  Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "Label:  1  & Label Category:  comp.graphics\n",
      "_________________________________________________________________________________________\n",
      "Message  2 :  \n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "\n",
      "Label:  3  & Label Category:  talk.religion.misc\n",
      "_________________________________________________________________________________________\n",
      "Message  3 :  \n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n",
      "\n",
      "Label:  2  & Label Category:  sci.space\n",
      "_________________________________________________________________________________________\n",
      "Message  4 :  I have a request for those who would like to see Charley Wingate\n",
      "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
      "appear to be quite a few of you.)  \n",
      "\n",
      "It is clear that Mr. Wingate intends to continue to post tangential or\n",
      "unrelated articles while ingoring the Challenges themselves.  Between\n",
      "the last two re-postings of the Challenges, I noted perhaps a dozen or\n",
      "more posts by Mr. Wingate, none of which answered a single Challenge.  \n",
      "\n",
      "It seems unmistakable to me that Mr. Wingate hopes that the questions\n",
      "will just go away, and he is doing his level best to change the\n",
      "subject.  Given that this seems a rather common net.theist tactic, I\n",
      "would like to suggest that we impress upon him our desire for answers,\n",
      "in the following manner:\n",
      "\n",
      "1. Ignore any future articles by Mr. Wingate that do not address the\n",
      "Challenges, until he answers them or explictly announces that he\n",
      "refuses to do so.\n",
      "\n",
      "--or--\n",
      "\n",
      "2. If you must respond to one of his articles, include within it\n",
      "something similar to the following:\n",
      "\n",
      "    \"Please answer the questions posed to you in the Charley Challenges.\"\n",
      "\n",
      "Really, I'm not looking to humiliate anyone here, I just want some\n",
      "honest answers.  You wouldn't think that honesty would be too much to\n",
      "ask from a devout Christian, would you?  \n",
      "\n",
      "Nevermind, that was a rhetorical question.\n",
      "\n",
      "Label:  0  & Label Category:  alt.atheism\n",
      "_________________________________________________________________________________________\n",
      "Message  5 :  AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\n",
      "May 7th  at Crystal City Virginia, under the auspices of AIAA.\n",
      "\n",
      "Does anyone know more about this?  How much, to attend????\n",
      "\n",
      "Anyone want to go?\n",
      "\n",
      "Label:  2  & Label Category:  sci.space\n",
      "_________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "P1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onfno6uHFsxm"
   },
   "source": [
    "### Part 2:\n",
    "\n",
    "Use CountVectorizer to turn the raw training text into feature vectors. You should use the fit_transform function, which makes 2 passes through the data: first it computes the vocabulary (\"fit\"), second it converts the raw text into feature vectors using the vocabulary (\"transform\").\n",
    "\n",
    "The vectorizer has a lot of options. To get familiar with some of them, write code to answer these questions:\n",
    "\n",
    "a. The output of the transform (also of fit_transform) is a sparse matrix: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html. What is the size of the vocabulary? What is the average number of non-zero features per example? What fraction of the entries in the matrix are non-zero? Hint: use \"nnz\" and \"shape\" attributes.\n",
    "\n",
    "b. What are the 0th and last feature strings (in alphabetical order)? Hint: use the vectorizer's get_feature_names function.\n",
    "\n",
    "c. Specify your own vocabulary with 4 words: [\"atheism\", \"graphics\", \"space\", \"religion\"]. Confirm the training vectors are appropriately shaped. Now what's the average number of non-zero features per example?\n",
    "\n",
    "d. Instead of extracting unigram word features, use \"analyzer\" and \"ngram_range\" to extract bigram and trigram character features. What size vocabulary does this yield?\n",
    "\n",
    "e. Use the \"min_df\" argument to prune words that appear in fewer than 10 documents. What size vocabulary does this yield?\n",
    "\n",
    "f. Using the standard CountVectorizer, what fraction of the words in the dev data are missing from the vocabulary? Hint: build a vocabulary for both train and dev and look at the size of the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyVwk5RvFsxn"
   },
   "outputs": [],
   "source": [
    "def P2():\n",
    "    \"\"\" P2 - Use CountVectorizer to turn the raw training text into feature vectors.\n",
    "    # param: None\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #a.) What is the size of the vocabulary? What is the average number of non-zero features per example? \n",
    "    # What fraction of the entries in the matrix are non-zero? \n",
    "    print('Part A')\n",
    "    \n",
    "    #sets countVectorizr and fits the training data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "\n",
    "    #prints size and total number of non-zero features\n",
    "    print('Size of Vocabulary: ', X.shape[1])\n",
    "    print('Total Number of Non-Zero Features: ', X.nnz)\n",
    "\n",
    "    #calculates the average number of non-zero features per example\n",
    "    sums = X.sum(axis=1).A1\n",
    "    counts = np.diff(X.indptr)\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    averages = sums / counts\n",
    "\n",
    "    #prints the average number of non-zero features per example\n",
    "    np.set_printoptions(precision=3, threshold=np.inf)\n",
    "    print('Average Number of Non-Zero Features per Example: ', averages)\n",
    "\n",
    "    #prints the fraction of the entries in the matrix that are non-zero\n",
    "    print('Fraction of Non-Zero Entries in the Matrix: ', X.nnz, '/', (X.shape[0] * X.shape[1]))\n",
    "    print('Sparsity: %.2f%%' % (100 * X.nnz /\n",
    "                                 (X.shape[0] * X.shape[1])))\n",
    "    \n",
    "    #b.) What are the 0th and last feature strings (in alphabetical order)? \n",
    "    print('\\nPart B')\n",
    "    \n",
    "    last_index = len(vectorizer.get_feature_names())-1\n",
    "    print('First Feature String: ', vectorizer.get_feature_names()[0])\n",
    "    print('Last Feature String: ',vectorizer.get_feature_names()[last_index])\n",
    "\n",
    "    #c.) Specify your own vocabulary with 4 words: [\"atheism\", \"graphics\", \"space\", \"religion\"]. \n",
    "    # Confirm the training vectors are appropriately shaped. \n",
    "    # Now what's the average number of non-zero features per example?\n",
    "    print('\\nPart C')\n",
    "    \n",
    "    #set countVectorizer with specified vocabulary\n",
    "    my_vocab = [\"atheism\", \"graphics\", \"space\", \"religion\"]\n",
    "    vect = CountVectorizer(vocabulary=my_vocab)\n",
    "\n",
    "    #confirm the training vectors are appropriately shaped\n",
    "    if type(train_data) == list:\n",
    "        print('Training vectors are are appropriately shaped.')\n",
    "\n",
    "    #fit to training data\n",
    "    dtm = vect.fit_transform(train_data)\n",
    "\n",
    "    #calculate average number of non-zero features per example\n",
    "    sums = dtm.sum(axis=1).A1\n",
    "    counts = np.diff(dtm.indptr)\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    averages = sums / counts\n",
    "\n",
    "    #print average number of non-zero features per example\n",
    "    np.set_printoptions(precision=3, threshold=np.inf)\n",
    "    print('Updated Average Number of Non-Zero Features per Example: ', averages)\n",
    "    \n",
    "    #d.) Instead of extracting unigram word features, use \"analyzer\" and \"ngram_range\" to extract bigram and trigram \n",
    "    # character features. What size vocabulary does this yield?\n",
    "    print('\\nPart D')\n",
    "    \n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "    print('Updated Size of Vocabulary: ', X.shape[1])\n",
    "    \n",
    "    #e.) Use the \"min_df\" argument to prune words that appear in fewer than 10 documents. \n",
    "    # What size vocabulary does this yield?\n",
    "    print('\\nPart E')\n",
    "    \n",
    "    vectorizer = CountVectorizer(min_df = 10)\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "    print('Updated Size of Vocabulary: ', X.shape[1])\n",
    "    \n",
    "    #f.) What fraction of the words in the dev data are missing from the vocabulary? \n",
    "    print('\\nPart F')\n",
    "    \n",
    "    #set countVectorizer for training data\n",
    "    vectorizer_train = CountVectorizer()\n",
    "    X_train = vectorizer_train.fit_transform(train_data)\n",
    "\n",
    "    #set countVectorizer for dev data\n",
    "    vectorizer_dev = CountVectorizer()\n",
    "    X_dev = vectorizer_dev.fit_transform(dev_data)\n",
    "\n",
    "    #print sizes for each countVectorizer\n",
    "    print('Size of Train Vocabulary: ', X_train.shape[1])\n",
    "    print('Size of Dev Vocabulary: ', X_dev.shape[1])\n",
    "\n",
    "    #get the vocabularies for each countVectorizer\n",
    "    x = vectorizer_train.vocabulary_\n",
    "    y = vectorizer_dev.vocabulary_\n",
    "    \n",
    "    #print the amount of words in both vocabularies\n",
    "    print('# Words in Both Training and Dev: ', len(x.keys() & y.keys()))\n",
    "    \n",
    "    #print the fraction of words that are in the dev data, but not in the vocabulary\n",
    "    print('Fraction of Words in Dev NOT in Vocabulary: ', (X_dev.shape[1] - len(x.keys() & y.keys()))/ X_dev.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part A\n",
      "Size of Vocabulary:  26879\n",
      "Total Number of Non-Zero Features:  196700\n",
      "Average Number of Non-Zero Features per Example:  [1.5   1.085 1.158 1.609 1.061 1.383 1.275 1.394 1.179 1.286 1.349 1.222\n",
      " 1.3   1.143 1.247 1.115 2.037 1.31  1.097 1.404 1.2   1.286 1.133 2.241\n",
      " 2.123 1.463   nan 1.275   nan 1.111 1.163 1.25  1.242 1.83  1.546 1.506\n",
      " 1.15  1.152 1.346 1.743 1.184 1.63  1.973 1.074 1.216 1.111 1.984 1.852\n",
      " 1.    1.377 1.633 1.465 3.686 1.526 1.293 1.538 1.04  1.264 1.364 1.067\n",
      " 1.5   1.    1.333 1.088 1.262 1.351 1.271 1.765 1.22  1.319 1.23  1.088\n",
      " 1.111 1.179 1.395 1.243   nan 1.311 1.217 1.    1.772 1.1   3.964 1.942\n",
      " 1.143 1.326 1.529 1.934 1.349 1.219 1.447 1.226 1.083 1.167 1.031 1.571\n",
      " 1.062 1.317 1.283 1.194 1.762 1.    1.338 1.363   nan 1.704 1.409 1.308\n",
      " 1.    1.311 1.111 1.265 1.268 1.    1.29  1.614 1.25  1.158 1.151 2.156\n",
      " 1.558 1.3   1.2   1.495 1.299 1.097 1.867 2.274 1.152 1.31  1.606 2.204\n",
      " 1.103 1.    1.304 1.118 1.282 1.043 2.009 1.669 2.177 1.169 1.389 1.325\n",
      " 3.339 1.12  1.182 1.174 1.2   1.278 1.211 1.558 1.094 1.102 2.228 1.493\n",
      " 1.269 1.133 1.208 1.277 1.909 1.273 1.685 1.    1.565 1.216 2.115 2.557\n",
      " 1.2   1.324 1.    1.95  1.672 1.293 1.354 1.182 1.405 1.083 1.121 1.\n",
      " 1.079 1.174 1.531 1.574 1.778   nan 1.083 1.676 1.736 1.592 1.935   nan\n",
      " 1.312 1.075 1.25  1.15  1.32  1.616 1.464 1.091 1.    1.513 1.259 1.158\n",
      "   nan 1.424 1.152 1.25  1.743 1.186 1.421 1.686 1.273 1.083 1.273 1.288\n",
      " 1.    2.657 1.532 1.315 1.397 1.316 1.17  1.403 1.908 1.46  1.    1.483\n",
      " 1.    1.975 1.195 1.319 1.193 1.289 1.    2.508 1.545 1.196 1.034 1.132\n",
      " 1.538 1.275 1.19  1.231 1.226 1.25  1.367 1.415 2.217 1.362 1.356 1.288\n",
      " 1.978 1.303 1.444 1.169 2.28  1.2   1.409 1.297 2.008 1.05  2.342 1.118\n",
      " 1.936 1.478 1.667 1.    1.045 1.143 1.125 1.    2.455 1.177 2.05  1.208\n",
      " 1.4   1.3   1.596 1.047 1.191 1.406 1.535 1.289 1.125 2.405 1.074 1.93\n",
      " 1.184 1.391 1.711 1.029 2.424 1.03  1.427 1.295 1.454 1.403 1.283 1.231\n",
      " 1.488 1.034 1.138 1.364 1.    1.293 1.053 1.5   1.119 1.221 1.479 1.\n",
      " 1.143 1.64  1.    1.25  1.41  1.82  1.419 1.848 1.542 1.247 1.366 2.006\n",
      " 1.556 1.232 1.471 1.103 1.143 1.453 1.    1.362 1.136 1.14  1.351 1.309\n",
      " 1.225 1.15  1.226 1.414   nan 1.276 1.038 1.298 1.083 1.293 1.176 1.486\n",
      " 1.196 1.218 1.067 1.182 1.439 1.684 1.573 1.138 1.156 1.324 1.156 1.256\n",
      " 1.139 1.24  1.633   nan 1.492 1.154 1.288 1.712 1.03  1.056 1.953 1.366\n",
      " 2.173 1.061 1.652 1.067 1.524 1.105 1.1   1.5   1.361 1.254 1.077 1.074\n",
      " 1.446 1.333 1.588 1.699 1.396 1.816 1.275 1.    1.811 1.506 1.276   nan\n",
      " 1.167 1.375 1.641 1.091   nan 1.97  1.25  1.115 1.2   1.592 3.074 1.567\n",
      " 1.273 1.355 1.125 1.59  1.304 1.243 1.25  1.553 1.318 1.087 1.344 1.286\n",
      "   nan 1.633 1.534 1.492 1.828 1.549 1.88  1.128 2.02  1.19  1.077 2.236\n",
      " 1.242 1.062 1.888 2.229 1.317 1.083 1.605 1.327 1.419 1.185 1.432   nan\n",
      " 1.397 1.394 1.255 1.315 1.036 1.434 1.137 1.631   nan 1.279 2.372 1.476\n",
      " 1.229 1.395 1.626 1.043 1.182 1.111 1.037 2.363 1.073 1.    1.673 1.935\n",
      " 1.031 1.463 1.414 1.414 1.42  1.174 2.265 1.244 1.258 1.067 1.405 1.775\n",
      "   nan 2.385 1.383 1.031 1.179 1.565 1.16  1.713 1.2   1.5   1.618 1.359\n",
      " 1.194 1.261 1.111 1.094 1.346 1.348 1.05  1.231 1.042 1.255 1.503 2.706\n",
      " 1.695 2.045 1.    1.183   nan 1.539 1.06  1.075 1.27  1.298 1.419 1.283\n",
      " 1.615   nan 2.083 1.    2.105 2.09  1.482 1.349 1.377 1.056 1.707 1.133\n",
      " 1.341 1.    1.268 1.752 1.462 1.324 1.43  2.176 1.565 1.712 1.    1.062\n",
      " 1.379 1.412 1.205 1.41  1.174 1.679 1.447 1.459 1.846 1.386 1.071 1.\n",
      " 1.797 2.002 1.    1.915 1.25  2.504 1.811 1.418 2.104 2.005 1.426 1.383\n",
      " 2.266 1.194 2.712   nan 1.1   2.243 1.356 1.134 1.172 2.141 1.167 1.793\n",
      " 1.256 1.95  1.    1.171 1.114 1.167 1.545 1.275 1.    1.729 1.175 1.1\n",
      " 1.346 1.581 1.    1.167 1.316 1.548 1.3   1.229 1.111 1.182 1.938 1.191\n",
      " 1.    1.121 1.207 1.565   nan   nan 1.115 2.046 1.453 1.286 1.379 1.538\n",
      " 1.51  1.145 1.667 1.194 1.171 1.698 2.212 1.667 1.059 1.318 1.    1.65\n",
      " 1.494 1.228 1.2   1.643 1.222 1.196 1.28  1.564 1.25  1.28  1.238 1.074\n",
      " 1.    1.635 1.802 1.    1.699 1.754 1.189 1.097 1.    1.643 1.    1.083\n",
      " 1.163 1.265 1.091 1.357 1.317 1.067 1.42  1.192 1.111 1.24  1.194 1.962\n",
      " 1.234 1.273 1.312 1.182 1.074 1.513 1.    1.711 1.761   nan 1.963 1.222\n",
      " 1.    1.05  1.612 1.    1.172 2.265 1.761 1.    1.243 1.328 1.749 1.669\n",
      " 1.125 1.927 1.394   nan 1.    1.233 1.397 1.333 1.194 1.111 1.167 1.919\n",
      " 1.361 1.397 2.138 1.947 1.065 2.071 1.232 1.25  1.048 1.275 1.462 1.128\n",
      " 2.195 1.297 1.    1.182 1.467 1.41  1.125 1.24  1.1   1.188 1.439 1.25\n",
      " 1.262 1.143 1.337 1.222 1.118 1.349 1.    1.99  1.898 2.034 1.265 1.203\n",
      " 2.297 1.711 1.074 1.167 1.467 1.263 1.427 1.071 1.128 1.207 1.265 1.\n",
      " 1.505 1.39  2.394 1.444 1.159 1.212 1.133 1.053 1.511 1.209 1.637 1.259\n",
      " 1.125 1.494 1.043 1.189 1.154 1.143 1.288 1.333 2.255 1.16  1.682 1.413\n",
      " 2.055 2.316 1.449 1.314 1.067 1.288 2.16  1.594 1.135 1.097 1.356 1.989\n",
      " 1.171 1.526 1.    1.194 2.542 1.536 1.357   nan 1.22  1.178 1.    1.235\n",
      " 2.163 1.316 1.    1.858 1.344 1.504 2.039 1.65    nan 1.    1.661 1.312\n",
      " 1.139 1.326 1.113 1.424 1.095 1.023 1.338 1.346 1.    1.546 1.319 1.389\n",
      " 1.418 1.038 1.273 1.382 2.676 1.4   1.293 1.086 1.437 1.179 1.642 1.125\n",
      " 2.292 1.652 1.056 1.278 1.831 1.045 1.351 1.393 1.364 1.378 1.625 2.767\n",
      " 1.938 1.702 1.278   nan 1.707 1.212 1.167 1.742 2.    1.149 1.738   nan\n",
      " 1.    1.326 1.1   1.059 1.087 1.111 1.258 1.615 1.239 1.235 1.115 1.087\n",
      " 1.043 1.172 1.207 1.453 2.259 1.438 1.149 1.24  1.18  1.961 2.818 2.248\n",
      " 1.558 1.431 1.18  4.927   nan 1.4   1.623 1.095 1.222 1.158 1.563 1.375\n",
      " 1.959 1.297 1.596 1.209 1.037 2.353 1.529 1.462   nan 1.359 1.152 1.478\n",
      " 1.36  1.143 1.304 1.105 1.133 1.236 1.861 1.442 1.071 1.411 1.906 1.07\n",
      " 1.36  1.    1.514 1.207 3.509   nan 1.    1.109 1.568 1.    1.462 1.182\n",
      " 1.145 1.    1.571 1.038 1.    1.679   nan   nan 1.149 1.    1.213 1.188\n",
      " 1.05  1.047 1.    1.353 1.994 1.402 1.1   1.63  1.377 2.03  1.    1.2\n",
      " 1.062 1.833 1.33  1.349 1.435 1.738 1.472 1.398 1.458 1.833 1.344 1.125\n",
      "   nan 1.053 1.543 1.238 1.486 1.125 2.022 1.741 1.273 1.642 1.295 2.06\n",
      " 1.924 2.604 1.317 1.443 2.114 1.403 1.135 1.118 1.269 2.232 1.12  1.414\n",
      " 1.    1.226 1.    2.556 1.548 1.673 1.104   nan 1.898 1.326 1.15  1.395\n",
      " 1.    1.4   1.573 1.543 1.627 1.271 1.847 1.309 1.053 1.105 1.061 1.133\n",
      " 1.184 1.772 1.276 1.154 2.485 1.054   nan 1.534 1.083 1.214 1.353 1.621\n",
      " 1.297 1.459 1.036 1.062 1.4   2.627 2.546 1.715 1.217 1.056 1.35  1.635\n",
      " 1.    1.037 2.121 1.    1.438 1.269 1.091 2.764 1.385 1.584 2.717 1.\n",
      " 1.368 1.133 1.371 1.31  1.611 1.451 2.288 1.065 1.192 1.22  1.294 1.097\n",
      " 1.339 1.776 1.116 1.15  1.    1.493 1.25  1.205 1.36  1.115 1.368 2.135\n",
      " 1.179 1.051 1.074 1.295 1.116 1.938 1.509 1.18    nan 1.533 1.236 1.524\n",
      " 1.188 1.324 2.424   nan 1.19  1.801 1.833 1.5   1.271 1.288 1.333 1.766\n",
      " 1.413 1.77  1.524 3.513 1.267 2.278 1.302 1.031 1.365 1.295 1.238 1.248\n",
      " 1.879 1.951 1.549 1.    1.    1.143 1.4   1.19  1.25  1.106 1.071 1.048\n",
      " 1.243 1.976 1.348 1.    1.119 1.143 1.5   1.19  1.286 1.5   1.658 1.233\n",
      " 1.342 1.077 1.759 1.    2.525 1.    1.188 1.408 1.175 1.095 1.    1.176\n",
      " 1.105 1.19  1.254 1.615 1.114 1.03  1.292 1.233   nan 1.    1.305 1.045\n",
      " 1.    1.    1.804 1.259 1.519 1.598 1.256 1.333 1.417 1.834 1.56  2.2\n",
      " 1.167 1.189 1.133 1.233 1.706 1.167 1.439 1.348 1.    1.    1.422 1.154\n",
      " 1.4   1.478 1.196 1.32  1.713 1.319 1.819 1.455 1.125 1.057 1.305 1.348\n",
      " 1.409 1.351 1.167 1.685 1.167 1.61  1.279 1.043   nan 1.205 1.442 1.328\n",
      " 1.083 1.68  1.316 1.574 1.184 1.    1.517 1.681 1.65  1.407 1.212 1.43\n",
      "   nan 1.    2.    1.147 1.27  1.205 1.065 1.446 1.683 1.439 1.119 1.231\n",
      " 1.154 1.196 1.1   1.549 1.333 1.656 1.333 1.102 1.312 1.544 1.38  1.069\n",
      " 1.425 1.151 1.324   nan 1.091 1.712 1.224 1.28  1.302 1.178 1.094 1.188\n",
      " 1.286 1.123 1.483 1.222 1.071 1.468 1.296 1.229 1.571 1.236 1.405 1.271\n",
      " 1.296 1.917   nan 1.138 1.171 1.186 1.626 2.034 1.163 1.211 1.301 1.094\n",
      " 1.396 1.413 1.233 1.382 1.58  1.111 1.    1.211 2.071 1.529 1.525 1.118\n",
      " 1.333 1.333 1.156 2.075 1.    1.423 1.033 1.404 1.    1.6   1.13  1.034\n",
      " 1.24  1.275 1.256 1.296 1.234 1.    1.179 1.484 1.    1.029 1.158 1.087\n",
      " 1.693 1.336 1.641 1.348 1.161 1.229 1.103 1.629 1.659 1.291 1.773 1.315\n",
      " 1.469 1.363 1.616 1.402 1.404 2.099 1.786 1.    1.022 1.2   1.28  1.\n",
      " 1.353 1.133 1.167 1.125 1.763 1.495 1.176 1.    1.453 1.641 1.439 1.078\n",
      " 1.893 1.    1.077 1.105 1.136 1.324 1.39  1.111 1.286 1.211 1.081 1.327\n",
      " 2.261 1.649 2.048 1.739 1.538 1.669 1.147 1.073 2.643 1.154 1.094 1.17\n",
      " 1.968 1.077 1.274 1.276 1.065 1.    1.167 1.438 1.835 1.    1.61  1.984\n",
      " 1.137 1.    1.155 1.083 1.826 1.37  2.194 1.167   nan 1.541 1.162 1.939\n",
      " 1.184   nan 1.289 1.278 1.286 1.083 1.364 1.037 1.232 1.663 1.213 1.835\n",
      " 1.718 1.12  1.244 1.298 1.111 1.182 1.467 2.771 1.494 1.    1.444 1.\n",
      " 1.464 1.407 1.515 1.056 1.224 1.3   1.365 1.127 1.365 1.603 1.17  1.466\n",
      " 1.107 1.898 1.12  1.606 1.281 4.692 1.095 1.148 1.494 1.519 1.283 1.105\n",
      " 1.123 1.67  1.358 1.42  1.925 1.339 1.341 1.423 2.167 1.2   1.056 1.04\n",
      " 1.275 1.475 1.304 1.257 1.071 2.    1.325 1.182 1.074 1.233 1.45  1.64\n",
      " 1.635 1.034 1.543 1.    1.481 1.25  1.329 1.098 1.226 1.368 1.656 1.207\n",
      " 1.13  1.333 1.175 1.111 1.    1.802 1.    1.551 1.701 1.222 1.961 1.115\n",
      " 1.944 1.148 1.407 1.222 1.397 1.162 2.616 1.707 1.889 1.    1.098 1.317\n",
      " 1.642 1.263 1.292 1.083 1.2   1.    1.312 1.536 1.262 1.5   1.    1.176\n",
      " 1.097 1.176 1.    1.31  1.143 1.444 2.007 1.362 1.435 1.564 1.12  1.208\n",
      " 1.575 1.    1.143 2.972 1.056 1.69  1.185 1.321 1.148 1.436 1.1   1.24\n",
      " 1.29  1.231 2.175 1.337 1.268 1.167 1.103 1.196 1.229 1.056 1.    1.436\n",
      " 1.547 1.231 1.125 1.371 1.495 1.    1.053 1.    1.364 2.385 1.032 1.143\n",
      " 1.945 1.764 1.323 1.716 1.385 1.133 2.033 1.114 3.52  1.36  2.    2.057\n",
      " 1.957 1.271 1.266 1.    1.571 1.288 2.781 1.344 1.196 1.212 1.799 1.179\n",
      " 1.571 1.728 1.057 1.29  1.875 1.194 2.003 1.182 1.324 1.091   nan 1.171\n",
      " 1.766 1.136 1.442 1.091 1.139 1.229 1.588 1.321 1.2   1.806 1.091 1.408\n",
      " 1.171 1.887 1.24  1.351 1.175 1.    1.434 1.604 1.571 1.221 1.083 1.935\n",
      " 1.037 1.136 1.186 1.378 1.357 1.293 1.151 1.    1.549 1.333 1.259 1.368\n",
      " 1.569 1.351 1.236 1.    1.326 2.435 1.089 1.214 1.954 1.205 1.565   nan\n",
      " 1.709 4.094 1.065 1.258 1.378 1.318 1.47  1.294   nan 1.878 1.235   nan\n",
      " 1.46  2.14  1.563 1.286 1.196 2.476 1.593 1.    2.48  1.067 1.231 1.182\n",
      " 1.148 1.571 1.473 1.224 1.133 1.205 1.34  1.    1.441 1.    1.256 1.219\n",
      " 1.212 1.563 1.969 1.364 1.716 1.487   nan 1.713 1.261 1.361 3.891 1.227\n",
      " 1.136 1.605 1.062 1.835 1.13  2.416 1.636 1.176 1.194 1.64  1.442 1.17\n",
      " 1.281 1.071 1.381 1.362 2.198 1.34    nan 1.508 1.52  1.408 1.611 1.\n",
      " 1.115 1.135 1.365 1.341 1.256 1.077 1.625 3.25  1.324 1.672 1.483 1.353\n",
      " 1.138 1.782 1.466 1.604 1.281 3.389 1.    1.328 1.222 1.062 1.192 1.364\n",
      " 1.558 1.351 1.34  1.359 1.703 1.25  2.164 1.176 1.411 1.204 1.176 1.519\n",
      " 1.    1.799 2.19  1.188 2.209 2.319 1.74  1.071 1.377 1.295 1.053 1.186\n",
      " 1.069 1.5   1.161 1.237 1.127 1.    1.29  1.514 1.    1.378 1.515 1.534\n",
      "   nan 1.533 1.    1.553 1.514 1.194 1.472 2.041 1.402 1.81  1.128 1.\n",
      " 1.162 1.122 1.188 1.091 2.206 1.208   nan 1.175 1.232 1.188 2.222 2.192\n",
      " 1.25  1.321 1.304 5.143 1.474 1.333 1.178   nan 1.826 1.632 1.087 1.077\n",
      "   nan 1.604 1.143 1.342 1.069 1.    1.293 1.81  1.467 1.549 1.077 1.348\n",
      " 1.341 1.987 1.179 1.448 1.116 1.    1.045 1.366 1.    1.593 1.824 1.404\n",
      " 1.158 1.526 1.566 1.    1.667 1.259 1.2   1.    1.443 2.083 1.365 1.54\n",
      " 1.598 1.52  1.171   nan 1.    1.259 1.369 1.943 1.344 1.048 2.    1.375\n",
      " 1.604 1.353 1.414 1.548 1.368 1.417 2.085 1.623 1.373 1.163 1.687 1.087\n",
      " 1.125 1.455 1.048 2.733 1.111 1.321 1.091 1.622 1.196 1.095 1.594 4.127\n",
      " 1.053 1.174 1.58  1.439   nan 1.286 1.114 1.429 1.238 1.211 1.466 1.323\n",
      " 1.15  1.479 1.838 1.387 1.484 1.13  1.275 1.043 2.389 1.851 2.061 1.578\n",
      " 1.143 1.111 1.184 1.062 1.346 1.456 1.426 1.274 1.903 1.    1.1   1.36\n",
      " 1.78  1.413 1.062 1.216 2.078   nan 2.2   1.067 1.278 1.143 1.091 1.029\n",
      " 1.562 1.05  1.321 1.129 1.269 1.056 1.149 1.426 1.083 1.424 1.361 2.091\n",
      " 1.062 1.543 1.    1.114 2.211 1.225 1.922 1.225 1.26  1.306 1.634 1.15\n",
      " 1.611 1.407 1.25  1.217 1.    1.294 1.312 1.193 1.455 1.869 1.    1.111\n",
      " 1.179 1.206 1.695 1.616 1.808 1.333 1.25  1.938   nan 1.23  1.725 1.\n",
      " 1.048 1.1   1.182 1.333 2.08  1.36  1.512 1.418 1.88  1.414 2.629 1.27\n",
      " 1.331 2.365 1.626 1.    1.257 1.355 1.458 1.116 1.      nan 1.923 1.667\n",
      " 1.424 1.431 1.207 1.411 1.192 1.475 2.012 2.152 1.133 1.757 1.529 1.077\n",
      " 1.261 1.1   1.105 1.382 1.5   1.9   1.111 1.228 1.862 1.81  1.15    nan\n",
      " 1.604 1.094 1.167 1.125 1.752   nan]\n",
      "Fraction of Non-Zero Entries in the Matrix:  196700 / 54671886\n",
      "Sparsity: 0.36%\n",
      "\n",
      "Part B\n",
      "First Feature String:  00\n",
      "Last Feature String:  zyxel\n",
      "\n",
      "Part C\n",
      "Training vectors are are appropriately shaped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Average Number of Non-Zero Features per Example:  [   nan    nan    nan    nan    nan    nan  1.       nan    nan  1.\n",
      "    nan    nan    nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan    nan    nan  1.       nan    nan    nan    nan    nan\n",
      "  1.       nan  4.     6.       nan  1.     1.       nan  1.       nan\n",
      "  1.       nan    nan    nan    nan    nan  1.       nan    nan  2.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan  1.\n",
      "    nan    nan    nan    nan  1.     1.     2.       nan    nan  1.\n",
      "  2.       nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan  5.       nan  1.     1.       nan    nan  2.       nan\n",
      "    nan  1.       nan  1.       nan    nan    nan    nan  1.       nan\n",
      "  1.       nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan  1.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan  2.       nan  2.     1.     1.       nan\n",
      "    nan 43.       nan    nan    nan  1.       nan  1.       nan  2.\n",
      "  2.       nan    nan  1.    26.       nan    nan    nan    nan  1.\n",
      "    nan    nan    nan    nan  3.       nan    nan    nan    nan    nan\n",
      "  2.       nan 31.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan    nan  4.     4.       nan    nan  2.       nan    nan\n",
      "    nan    nan  1.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  1.       nan  1.       nan\n",
      "    nan    nan  1.       nan  3.       nan    nan  2.     1.       nan\n",
      "    nan    nan  1.       nan    nan    nan    nan    nan    nan  1.\n",
      "    nan    nan    nan    nan    nan    nan    nan  2.       nan    nan\n",
      "    nan    nan    nan  1.       nan    nan    nan  4.       nan    nan\n",
      "    nan    nan    nan    nan  1.       nan    nan    nan    nan    nan\n",
      "    nan    nan  2.       nan    nan  2.       nan    nan    nan    nan\n",
      "    nan    nan  1.667    nan  1.       nan    nan    nan    nan  1.\n",
      "  1.     2.       nan    nan    nan  3.       nan    nan    nan    nan\n",
      "    nan    nan    nan  1.     1.     1.       nan    nan    nan  1.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  1.     2.\n",
      "  1.       nan    nan    nan    nan    nan    nan  7.     1.       nan\n",
      "    nan    nan    nan    nan    nan    nan  1.       nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  1.       nan\n",
      "    nan  1.       nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan  1.     2.       nan  1.       nan    nan    nan    nan    nan\n",
      "  1.       nan  1.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan  2.       nan    nan  1.       nan  3.       nan    nan  4.\n",
      "    nan    nan  2.     1.       nan    nan    nan  1.       nan    nan\n",
      "    nan    nan  1.       nan    nan  1.       nan    nan  2.     1.\n",
      "    nan    nan    nan  1.       nan    nan  2.       nan    nan    nan\n",
      "    nan  1.       nan    nan    nan  1.       nan    nan    nan    nan\n",
      "  1.     1.       nan    nan    nan  1.       nan    nan  1.       nan\n",
      "    nan  2.       nan    nan  4.       nan    nan  2.       nan    nan\n",
      "  1.       nan    nan    nan  3.     1.       nan    nan    nan  1.\n",
      "  1.       nan    nan  2.       nan    nan    nan    nan  1.       nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan 10.\n",
      "    nan  4.5    1.       nan    nan  4.       nan  2.       nan  3.\n",
      "    nan    nan    nan  1.       nan    nan    nan    nan  1.     1.\n",
      "  1.       nan    nan    nan  8.       nan    nan    nan    nan    nan\n",
      "    nan    nan    nan  2.       nan    nan    nan    nan 24.     1.\n",
      "  5.     1.       nan    nan    nan    nan  1.     1.     1.       nan\n",
      "    nan    nan  1.     1.     1.     6.     1.     1.       nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan  2.       nan    nan\n",
      "  1.       nan    nan 20.5      nan  5.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan  2.     5.       nan  1.     1.\n",
      "    nan  3.       nan 10.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan  1.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  1.       nan\n",
      "  1.     1.       nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan  4.     2.     4.       nan    nan  1.       nan    nan\n",
      "    nan  1.       nan 12.     5.     3.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan  1.     5.       nan\n",
      "  2.    23.       nan    nan    nan  3.       nan    nan    nan  1.\n",
      "    nan    nan    nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan    nan  1.     1.     2.       nan  2.       nan    nan\n",
      "  3.     2.       nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan  2.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  3.     1.     3.       nan\n",
      "    nan    nan  1.       nan  1.       nan    nan    nan 10.       nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan 12.\n",
      "    nan    nan    nan  1.       nan    nan    nan  1.       nan  1.\n",
      "    nan    nan  1.       nan    nan    nan  1.       nan    nan    nan\n",
      "    nan  1.       nan  1.       nan  1.       nan  3.       nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  3.     1.     2.     4.\n",
      "    nan    nan    nan    nan  1.       nan    nan    nan    nan  1.\n",
      "    nan    nan    nan  1.       nan  1.       nan    nan    nan  1.\n",
      "    nan    nan    nan  1.       nan  1.       nan    nan  1.     1.\n",
      "    nan    nan    nan    nan  2.       nan    nan    nan  1.       nan\n",
      "    nan    nan    nan    nan    nan  1.       nan    nan    nan    nan\n",
      "  1.       nan    nan    nan    nan  1.     1.       nan    nan    nan\n",
      "    nan    nan  2.       nan    nan    nan  3.       nan    nan 14.\n",
      "  1.       nan  2.       nan    nan    nan  1.       nan  3.       nan\n",
      "  2.5      nan    nan    nan    nan  1.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  1.     2.\n",
      "  1.       nan    nan  1.       nan    nan    nan    nan    nan  1.\n",
      "    nan    nan  2.       nan    nan    nan  1.       nan  2.       nan\n",
      "  4.       nan    nan 15.       nan    nan    nan  2.     2.       nan\n",
      "  2.       nan    nan    nan    nan  1.       nan    nan    nan    nan\n",
      "  7.       nan  1.       nan    nan    nan  9.5      nan    nan    nan\n",
      "    nan    nan    nan  2.       nan    nan    nan  1.       nan    nan\n",
      "    nan    nan    nan    nan  1.       nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan  2.       nan    nan    nan    nan\n",
      "  1.       nan    nan    nan    nan  1.     2.       nan    nan    nan\n",
      "    nan    nan  2.       nan    nan    nan  7.       nan  1.       nan\n",
      "    nan  2.       nan    nan    nan    nan    nan    nan    nan    nan\n",
      "  1.       nan    nan  4.       nan    nan  1.     1.       nan  6.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan  2.       nan  1.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan  1.       nan    nan    nan    nan    nan    nan  7.\n",
      "    nan  1.     1.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  1.       nan    nan  3.\n",
      "  2.     2.     1.       nan    nan  1.       nan  3.       nan  1.\n",
      "  1.       nan    nan    nan  2.       nan  1.     4.       nan    nan\n",
      "    nan    nan    nan    nan    nan  1.       nan    nan    nan    nan\n",
      "    nan    nan  1.     8.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan  1.       nan    nan    nan    nan    nan    nan    nan\n",
      "  1.       nan    nan    nan    nan  1.     1.       nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan  3.       nan    nan\n",
      "  1.       nan    nan    nan    nan    nan    nan    nan  2.       nan\n",
      "    nan    nan  1.5      nan    nan  2.       nan    nan    nan    nan\n",
      "    nan    nan  1.       nan    nan  1.     2.       nan    nan    nan\n",
      "    nan    nan    nan    nan  2.     1.       nan  2.       nan    nan\n",
      "  2.     3.       nan  3.       nan  2.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  1.     2.       nan    nan\n",
      "    nan    nan  2.       nan    nan    nan    nan    nan    nan  1.\n",
      "    nan    nan    nan    nan  3.       nan    nan    nan  1.     1.\n",
      "    nan    nan    nan  1.     2.       nan  1.       nan    nan    nan\n",
      "  1.     1.       nan    nan    nan    nan    nan    nan    nan    nan\n",
      "  1.       nan    nan    nan    nan  1.       nan    nan    nan  4.\n",
      "  1.       nan    nan  8.     1.       nan  1.     1.     1.       nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan  4.     1.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  2.       nan    nan    nan\n",
      "    nan  1.       nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan 12.       nan  3.\n",
      "  1.       nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan  1.       nan    nan    nan    nan    nan  1.\n",
      "    nan  3.       nan    nan    nan    nan    nan    nan  1.     1.\n",
      "    nan    nan  3.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan  1.     3.       nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan  1.       nan  2.       nan    nan    nan    nan    nan\n",
      "    nan    nan    nan  2.     1.       nan    nan    nan    nan  3.\n",
      "    nan  1.       nan    nan  2.       nan    nan    nan    nan  1.\n",
      "    nan    nan    nan  1.       nan    nan    nan    nan  4.       nan\n",
      "    nan    nan    nan    nan  1.       nan  1.       nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  3.       nan    nan    nan\n",
      "    nan  1.       nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan  3.     2.       nan    nan    nan  1.\n",
      "  1.       nan  1.     2.5      nan    nan  1.       nan  1.       nan\n",
      "    nan    nan    nan    nan    nan  2.       nan    nan  6.       nan\n",
      "    nan    nan  1.       nan  1.       nan  1.       nan  1.     1.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  1.       nan\n",
      "    nan    nan    nan    nan    nan  1.       nan    nan    nan    nan\n",
      "    nan  6.       nan    nan  1.       nan  9.     1.       nan    nan\n",
      "    nan    nan  4.       nan  2.     1.     1.       nan    nan    nan\n",
      "  1.       nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "  1.       nan    nan    nan    nan  2.       nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan  5.       nan    nan\n",
      "  1.       nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan  1.       nan  1.       nan    nan    nan    nan    nan  4.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan  2.       nan  1.     1.       nan    nan    nan 11.667  1.\n",
      "  8.       nan    nan    nan    nan    nan    nan    nan  5.       nan\n",
      "    nan    nan    nan    nan  1.       nan    nan  3.       nan    nan\n",
      "  8.       nan  2.       nan    nan    nan  1.     1.     2.       nan\n",
      "    nan    nan    nan    nan    nan  5.       nan    nan  1.     2.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan 34.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  1.     1.\n",
      "    nan    nan    nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan  1.       nan    nan    nan  1.     1.       nan  1.       nan\n",
      "    nan    nan    nan  1.       nan    nan    nan    nan  1.       nan\n",
      "    nan    nan    nan    nan  4.       nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  4.       nan  2.       nan\n",
      "    nan  1.     3.       nan    nan    nan    nan    nan  2.     1.\n",
      " 71.     2.       nan  1.       nan  1.       nan    nan    nan    nan\n",
      "    nan    nan  1.       nan    nan    nan    nan  6.    71.       nan\n",
      "    nan    nan    nan  2.       nan    nan    nan    nan    nan    nan\n",
      "  3.       nan    nan 21.5    1.       nan    nan    nan    nan    nan\n",
      "  1.       nan    nan 56.5      nan    nan    nan    nan    nan  2.\n",
      "  1.       nan    nan    nan  6.       nan 26.       nan    nan    nan\n",
      "    nan  1.       nan    nan    nan  1.     2.    12.       nan    nan\n",
      "  2.       nan    nan  1.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan  3.       nan    nan  1.       nan\n",
      "    nan    nan 10.       nan    nan    nan    nan    nan  4.    20.\n",
      "  1.     1.       nan 13.       nan    nan  1.       nan  1.       nan\n",
      "  1.       nan    nan    nan    nan    nan    nan    nan  2.       nan\n",
      "    nan  2.       nan    nan  1.     1.     1.       nan  1.       nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  3.     1.       nan  3.\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan  2.       nan\n",
      "  1.       nan    nan  1.       nan  1.       nan  2.       nan  1.\n",
      "    nan    nan    nan  2.       nan 19.     1.     1.       nan    nan\n",
      "  1.       nan  2.    38.       nan    nan  1.     4.       nan    nan\n",
      "    nan  2.       nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan    nan  1.    56.       nan  4.5      nan    nan    nan\n",
      "  2.     1.     2.     1.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan  1.     1.       nan  3.       nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan  2.       nan  1.     3.\n",
      "    nan    nan    nan    nan    nan 10.     1.       nan  1.     1.\n",
      "  1.       nan    nan  2.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan  7.     1.       nan  1.       nan\n",
      "  7.     3.       nan    nan    nan    nan    nan  1.       nan    nan\n",
      "    nan    nan    nan    nan    nan  2.       nan    nan  5.       nan\n",
      "    nan    nan    nan  3.       nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "  9.     8.     1.     1.       nan    nan    nan    nan  1.       nan\n",
      "    nan    nan    nan  1.       nan  3.5      nan    nan  2.       nan\n",
      "    nan    nan  1.       nan]\n",
      "\n",
      "Part D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Size of Vocabulary:  35478\n",
      "\n",
      "Part E\n",
      "Updated Size of Vocabulary:  3064\n",
      "\n",
      "Part F\n",
      "Size of Train Vocabulary:  26879\n",
      "Size of Dev Vocabulary:  16246\n",
      "# Words in Both Training and Dev:  12219\n",
      "Fraction of Words in Dev NOT in Vocabulary:  0.24787640034470024\n"
     ]
    }
   ],
   "source": [
    "P2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydjkRh6LFsxp"
   },
   "source": [
    "### Part 3:\n",
    "\n",
    "Use the default CountVectorizer options and report the f1 score (use metrics.f1_score with average=\"weighted\") for a k nearest neighbors classifier; find the optimal value for k. Also fit a Multinomial Naive Bayes model and find the optimal value for alpha. Finally, fit a logistic regression model and find the optimal value for the regularization strength C using l2 regularization. A few questions:\n",
    "\n",
    "* Why doesn't nearest neighbors work well for this problem?\n",
    "* Any ideas why logistic regression doesn't work as well as Naive Bayes?\n",
    "* Logistic regression estimates a weight vector for each class, which you can access with the coef\\_ attribute. Output the sum of the squared weight values for each class for each setting of the C parameter. Briefly explain the relationship between the sum and the value of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VvhpODdWFsxp"
   },
   "outputs": [],
   "source": [
    "def P3():\n",
    "    \"\"\" P3 - Use CountVectorizer options to report the F1 scores for a kNN, Multinomial Naive Bayes, and \n",
    "                Logistic Regression classifier, all with different parameter settings.\n",
    "    # param: None\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #sets countVectorizr and fits the training and dev data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "    X_dev = vectorizer.transform(dev_data)\n",
    "    \n",
    "    #for the kNN classifier:\n",
    "    print('kNN Classifier: \\n')\n",
    "\n",
    "    #initialize variables\n",
    "    bestK = []\n",
    "    \n",
    "    #iterate through different values of k\n",
    "    k_values = [1, 3, 5, 7, 9]\n",
    "    for i in k_values:\n",
    "        \n",
    "        #train and fit the kNN model\n",
    "        knn = KNeighborsClassifier(n_neighbors = i)\n",
    "        knn.fit(X, train_labels)\n",
    "        \n",
    "        #evaluate on the dev data\n",
    "        y_pred = knn.predict(X_dev)\n",
    "        \n",
    "        #get array of F1-scores\n",
    "        bestK.append(metrics.f1_score(dev_labels, y_pred, average='weighted'))\n",
    "\n",
    "        #print the F1-scores for each value of k\n",
    "        print('For k = ',i, ', the F1-score is: ', metrics.f1_score(dev_labels, y_pred, average='weighted'))\n",
    "\n",
    "    #print the optimal value of k\n",
    "    my_k_index = np.argmax(bestK)\n",
    "    my_k = k_values[my_k_index]\n",
    "    print('\\nAs a result, the optimal value for k is', my_k, '.\\n')    \n",
    "    \n",
    "    #for the MNB classifier:\n",
    "    print('Multinomial Naive Bayes Classifier: \\n')\n",
    "\n",
    "    #initialize variables\n",
    "    bestA = []\n",
    "    \n",
    "    #iterate through different values of alpha\n",
    "    alphas = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "    for i in alphas:\n",
    "        \n",
    "        #train and fit the MNB model\n",
    "        MNBclf = MultinomialNB(alpha = i)\n",
    "        MNBclf.fit(X, train_labels)\n",
    "\n",
    "        #evaluate on the dev data\n",
    "        MNBy_pred = MNBclf.predict(X_dev)\n",
    "        \n",
    "        #get array of F1-scores\n",
    "        bestA.append(metrics.f1_score(dev_labels, MNBy_pred, average='weighted'))\n",
    "\n",
    "        #print the F1-scores for each value of alpha\n",
    "        print('For alpha = ',i, ', the F1-score is: ', metrics.f1_score(dev_labels, MNBy_pred, average='weighted'))\n",
    "\n",
    "    #print the optimal value of alpha\n",
    "    my_A_index = np.argmax(bestA)\n",
    "    my_A = alphas[my_A_index]\n",
    "    print('\\nAs a result, the optimal value for alpha is ', my_A, '.\\n')   \n",
    "    \n",
    "    #for the Log Reg classifier:\n",
    "    print('Logistic Regression Classifier: \\n')\n",
    "\n",
    "    #initialize variables\n",
    "    bestC = []\n",
    "    \n",
    "    #iterate through different values of C\n",
    "    C_values = [0.001,0.01,0.1,1,10]\n",
    "    for i in C_values:\n",
    "        \n",
    "        #train and fit the LR model\n",
    "        LRclf = LogisticRegression(penalty = 'l2', C = i, solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "        LRclf.fit(X, train_labels)\n",
    "\n",
    "        #evaluate on the dev data\n",
    "        LRy_pred = LRclf.predict(X_dev)\n",
    "        \n",
    "        #get array of F1-scores\n",
    "        bestC.append(metrics.f1_score(dev_labels, LRy_pred, average='weighted'))\n",
    "\n",
    "        #print the F1-scores for each value of alpha\n",
    "        print('For C = ',i, ', the F1-score is: ', metrics.f1_score(dev_labels, LRy_pred, average='weighted'))\n",
    "        \n",
    "        sum_sq_weights = []\n",
    "        for j in [0,1,2,3]:\n",
    "            temp = sum(np.square(LRclf.coef_)[j])\n",
    "            sum_sq_weights.append(temp)\n",
    "        print('\\nThe Sum of the Squared Weight Values for each Class:\\n', sum_sq_weights, '\\n')\n",
    "\n",
    "    #print the optimal value of C\n",
    "    my_C_index = np.argmax(bestC)\n",
    "    my_C = C_values[my_C_index]\n",
    "    print('\\nAs a result, the optimal value for alpha is ', my_C, '.\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Classifier: \n",
      "\n",
      "For k =  1 , the F1-score is:  0.3805030018531525\n",
      "For k =  3 , the F1-score is:  0.4084150225437623\n",
      "For k =  5 , the F1-score is:  0.4287607236218357\n",
      "For k =  7 , the F1-score is:  0.45047910006117586\n",
      "For k =  9 , the F1-score is:  0.4365666176198027\n",
      "\n",
      "As a result, the optimal value for k is 7 .\n",
      "\n",
      "Multinomial Naive Bayes Classifier: \n",
      "\n",
      "For alpha =  1e-10 , the F1-score is:  0.747240657284563\n",
      "For alpha =  0.0001 , the F1-score is:  0.7628348704826354\n",
      "For alpha =  0.001 , the F1-score is:  0.7702518836155706\n",
      "For alpha =  0.01 , the F1-score is:  0.7751663218544357\n",
      "For alpha =  0.1 , the F1-score is:  0.7903052385098862\n",
      "For alpha =  0.5 , the F1-score is:  0.7862862961995258\n",
      "For alpha =  1.0 , the F1-score is:  0.7777320236017224\n",
      "For alpha =  2.0 , the F1-score is:  0.7689966472342658\n",
      "For alpha =  10.0 , the F1-score is:  0.6674814338256576\n",
      "\n",
      "As a result, the optimal value for alpha is  0.1 .\n",
      "\n",
      "Logistic Regression Classifier: \n",
      "\n",
      "For C =  0.001 , the F1-score is:  0.5328493709625631\n",
      "\n",
      "The Sum of the Squared Weight Values for each Class:\n",
      " [0.09426742342117594, 0.15744849669377933, 0.12489112877970045, 0.08813422014457278] \n",
      "\n",
      "For C =  0.01 , the F1-score is:  0.6432052548920305\n",
      "\n",
      "The Sum of the Squared Weight Values for each Class:\n",
      " [1.5297689519056152, 2.030055915560553, 1.8659420174907027, 1.369431787234981] \n",
      "\n",
      "For C =  0.1 , the F1-score is:  0.6971054614079846\n",
      "\n",
      "The Sum of the Squared Weight Values for each Class:\n",
      " [14.088496719960027, 14.445433209126698, 15.47271616721066, 12.856093421303711] \n",
      "\n",
      "For C =  1 , the F1-score is:  0.6926515412432168\n",
      "\n",
      "The Sum of the Squared Weight Values for each Class:\n",
      " [72.14839819746979, 63.394840195107115, 72.84077655207263, 66.80322837815172] \n",
      "\n",
      "For C =  10 , the F1-score is:  0.670091352278488\n",
      "\n",
      "The Sum of the Squared Weight Values for each Class:\n",
      " [212.96883301451234, 179.78378301251254, 205.2109791198368, 200.8235680108896] \n",
      "\n",
      "\n",
      "As a result, the optimal value for alpha is  0.1 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWtXwAlOFsxr"
   },
   "source": [
    "ANSWER: \n",
    "\n",
    "* Why doesn't nearest neighbors work well for this problem?\n",
    "\n",
    "We can see that nearest neighbors does not work very well for this problem, with around 38-45% accuracy for different values of k. This is most likely because the data is not normalized. CountVectorizer implements both tokenization and occurrence counting in a single class, but does not weight the words according to their significance. So, some attributes can have greater influence on the classifications than others despite not being very significant for classification. Also, there are many dimensions in this dataset. The Euclidean distance is unhelpful in high dimensions because all vectors are almost equidistant to the search query vector. As a result, the kNN classifier does not perform very well.\n",
    "\n",
    "* Any ideas why logistic regression doesn't work as well as Naive Bayes?\n",
    "\n",
    "Logistic regression estimates the probabilities directly from the training data by minimizing error, making it a discriminative model, and assumes that the data is linearly separable. Multinomial Naive Bayes estimates a joint probability from the training data, making it a generative model, and assumes all the features are conditionally independent. We can see that logistic regression does not work as well as Naive Bayes for this problem. This is most likely because logistic regression is used for classification problems with two possible outcomes. In this context, we have four possible outcomes. Conversely, the Multinomial Naive Bayes classifier is used for classification with discrete features, such as word counts for text classification. Naive Bayes has a higher bias but lower variance compared to logistic regression. So, logistic regession is helpful in feature selection, but not necessarily classification as we can leverage the estimated probabilities instead of the binary predictions. As a result, Naive Bayes performs better than logisic regression in this problem.\n",
    "\n",
    "* Briefly explain the relationship between the sum and the value of C.\n",
    "\n",
    "There is a relationship between the sum of the squared weight values for each class and C. C represents the inverse of the regularization strength, so higher values of C correspond to less regularization. The weights are the coefficients of the features in the decision function, which indicates how the features impact the accuracy of the model. Regularization acts as a penalty against complexity. Increasing the regularization strength (meaning lowering C) penalizes \"large\" weight coefficients. As a result, the sum of the squared weight values for each class increase as the value of C increases. This is evident in our results from the Logistic Regression Model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGEjsm_uFsxr"
   },
   "source": [
    "### Part 4:\n",
    "\n",
    "Train a logistic regression model. Find the 5 features with the largest weights for each label -- 20 features in total. Create a table with 20 rows and 4 columns that shows the weight for each of these features for each of the labels. Create the table again with bigram features. Any surprising features in this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN51Nv4fFsxs"
   },
   "outputs": [],
   "source": [
    "def P4():\n",
    "    \"\"\" P4 - Trains a logistic regression model, finds the 5 features with the largest weights for each label, and\n",
    "                creates a table that shows the weights/features for each label. This process is then repeated for\n",
    "                bigram features.\n",
    "    # param: None\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "\n",
    "    #sets countVectorizr and fits the training data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "    \n",
    "    #trains the logistic regression model\n",
    "    LRclf = LogisticRegression(penalty = 'l2', C = 0.1, solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "    \n",
    "    #initialize variables\n",
    "    my_label = []\n",
    "    my_weight = []\n",
    "    my_features = []\n",
    "    my_category = []\n",
    "\n",
    "    #iterat through the topic categories\n",
    "    for i in [0,1,2,3]:\n",
    "        \n",
    "        #get the coefficients for the given label\n",
    "        coefs = LRclf.coef_[i]\n",
    "\n",
    "        #get the indexes for the top 5 weights, sorted\n",
    "        top_five = np.argpartition(coefs, -5)[-5:]\n",
    "        top_five_sorted=top_five[np.argsort(coefs[top_five])]\n",
    "\n",
    "        #map the label to its category\n",
    "        if i == 0:\n",
    "            lab_type = 'alt.atheism'\n",
    "        elif i == 1:\n",
    "            lab_type = 'comp.graphics'\n",
    "        elif i == 2:\n",
    "            lab_type = 'sci.space'\n",
    "        else:\n",
    "            lab_type = 'talk.religion.misc'\n",
    "\n",
    "        #add label, category, feature, and weight to columns\n",
    "        for j in top_five_sorted:\n",
    "            my_label.append(i)\n",
    "            my_category.append(lab_type)\n",
    "            my_features.append(vectorizer.get_feature_names()[j])\n",
    "            my_weight.append(coefs[j])\n",
    "        \n",
    "    print('Table for Top 5 Features per Label: \\n')\n",
    "    \n",
    "    print('\\tLabel \\t Category \\t\\t Feature \\t Weight\\n')\n",
    "\n",
    "    for k in range(0,len(my_label)):\n",
    "        if my_label[k] < 3:\n",
    "            if len(my_features[k]) >= 6:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t\\t', my_features[k], '\\t', my_weight[k])\n",
    "            else:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t\\t', my_features[k], '\\t\\t', my_weight[k])\n",
    "        else:\n",
    "            if len(my_features[k]) >= 6:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t', my_features[k], '\\t', my_weight[k])\n",
    "            else:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t', my_features[k], '\\t\\t', my_weight[k])\n",
    "    \n",
    "    \n",
    "    #sets countVectorizr and fits the training data for bigrams\n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "\n",
    "    #trains the logistic regression model\n",
    "    LRclf = LogisticRegression(penalty = 'l2', C = 0.1, solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "    \n",
    "    #initialize variables\n",
    "    my_label = []\n",
    "    my_weight = []\n",
    "    my_features = []\n",
    "    my_category = []\n",
    "\n",
    "    #iterate through the topic categories\n",
    "    for i in [0,1,2,3]:\n",
    "        \n",
    "        #gets the coefficients for the given label\n",
    "        coefs = LRclf.coef_[i]\n",
    "\n",
    "        #get the indexes for the top 5 weights, sorted\n",
    "        top_five = np.argpartition(coefs, -5)[-5:]\n",
    "        top_five_sorted=top_five[np.argsort(coefs[top_five])]\n",
    "\n",
    "        #map the label to its category\n",
    "        if i == 0:\n",
    "            lab_type = 'alt.atheism'\n",
    "        elif i == 1:\n",
    "            lab_type = 'comp.graphics'\n",
    "        elif i == 2:\n",
    "            lab_type = 'sci.space'\n",
    "        else:\n",
    "            lab_type = 'talk.religion.misc'\n",
    "\n",
    "        #add label, category, feature, and weight to columns\n",
    "        for j in top_five_sorted:\n",
    "            my_label.append(i)\n",
    "            my_category.append(lab_type)\n",
    "            my_features.append(vectorizer.get_feature_names()[j])\n",
    "            my_weight.append(coefs[j])\n",
    "    \n",
    "    print('\\nTable for Top 5 Bigram Features per Label: \\n')\n",
    "    \n",
    "    print('\\tLabel \\t Category \\t\\t Feature \\t Weight\\n')\n",
    "\n",
    "    for k in range(0,len(my_label)):\n",
    "        if my_label[k] < 3:\n",
    "            if len(my_features[k]) >= 6:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t\\t', my_features[k], '\\t', my_weight[k])\n",
    "            else:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t\\t', my_features[k], '\\t\\t', my_weight[k])\n",
    "        else:\n",
    "            if len(my_features[k]) >= 6:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t', my_features[k], '\\t', my_weight[k])\n",
    "            else:\n",
    "                print(k, '\\t', my_label[k], '\\t', my_category[k], '\\t', my_features[k], '\\t\\t', my_weight[k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for Top 5 Features per Label: \n",
      "\n",
      "\tLabel \t Category \t\t Feature \t Weight\n",
      "\n",
      "0 \t 0 \t alt.atheism \t\t islam \t\t 0.288119454192954\n",
      "1 \t 0 \t alt.atheism \t\t bobby \t\t 0.3387439631312303\n",
      "2 \t 0 \t alt.atheism \t\t atheists \t 0.35261550488706783\n",
      "3 \t 0 \t alt.atheism \t\t atheism \t 0.37874289845250225\n",
      "4 \t 0 \t alt.atheism \t\t religion \t 0.4069992175708825\n",
      "5 \t 1 \t comp.graphics \t\t files \t\t 0.3935134195576309\n",
      "6 \t 1 \t comp.graphics \t\t 3d \t\t 0.42053361779071413\n",
      "7 \t 1 \t comp.graphics \t\t file \t\t 0.5000225301396826\n",
      "8 \t 1 \t comp.graphics \t\t image \t\t 0.5109537610551879\n",
      "9 \t 1 \t comp.graphics \t\t graphics \t 0.7665748140669235\n",
      "10 \t 2 \t sci.space \t\t spacecraft \t 0.3028081177279911\n",
      "11 \t 2 \t sci.space \t\t launch \t 0.3521375313805326\n",
      "12 \t 2 \t sci.space \t\t nasa \t\t 0.4400085220778291\n",
      "13 \t 2 \t sci.space \t\t orbit \t\t 0.4529152174273725\n",
      "14 \t 2 \t sci.space \t\t space \t\t 0.9982445938569832\n",
      "15 \t 3 \t talk.religion.misc \t blood \t\t 0.3184137394132702\n",
      "16 \t 3 \t talk.religion.misc \t objective \t 0.32770765155700454\n",
      "17 \t 3 \t talk.religion.misc \t christian \t 0.40942392148779605\n",
      "18 \t 3 \t talk.religion.misc \t god \t\t 0.41478441517124076\n",
      "19 \t 3 \t talk.religion.misc \t christians \t 0.4211955249734184\n",
      "\n",
      "Table for Top 5 Bigram Features per Label: \n",
      "\n",
      "\tLabel \t Category \t\t Feature \t Weight\n",
      "\n",
      "0 \t 0 \t alt.atheism \t\t are you \t 0.2298758887096069\n",
      "1 \t 0 \t alt.atheism \t\t in this \t 0.23555596296467046\n",
      "2 \t 0 \t alt.atheism \t\t is not \t 0.23831936613560836\n",
      "3 \t 0 \t alt.atheism \t\t you are \t 0.24782393437533173\n",
      "4 \t 0 \t alt.atheism \t\t cheers kent \t 0.2676514215772693\n",
      "5 \t 1 \t comp.graphics \t\t comp graphics \t 0.31111885201659495\n",
      "6 \t 1 \t comp.graphics \t\t is there \t 0.34615027501465423\n",
      "7 \t 1 \t comp.graphics \t\t out there \t 0.3644235231196105\n",
      "8 \t 1 \t comp.graphics \t\t in advance \t 0.42513393352867584\n",
      "9 \t 1 \t comp.graphics \t\t looking for \t 0.5515306938290888\n",
      "10 \t 2 \t sci.space \t\t it was \t 0.2772147042316719\n",
      "11 \t 2 \t sci.space \t\t and such \t 0.2809739428512369\n",
      "12 \t 2 \t sci.space \t\t sci space \t 0.28458692160130494\n",
      "13 \t 2 \t sci.space \t\t the space \t 0.3926468499200312\n",
      "14 \t 2 \t sci.space \t\t the moon \t 0.40182981071398083\n",
      "15 \t 3 \t talk.religion.misc \t of god \t 0.20655513893682279\n",
      "16 \t 3 \t talk.religion.misc \t with you \t 0.21213511179866226\n",
      "17 \t 3 \t talk.religion.misc \t the bible \t 0.21578354398905933\n",
      "18 \t 3 \t talk.religion.misc \t the fbi \t 0.24638298947905193\n",
      "19 \t 3 \t talk.religion.misc \t cheers kent \t 0.2870009882038914\n"
     ]
    }
   ],
   "source": [
    "P4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cY67F-tXFsxt"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "* Any surprising features in this table?\n",
    "\n",
    "There are a few surprising features in these tables.\n",
    "\n",
    "In the uni-gram table, the feature 'bobby' is in the top 5 largest weights for alt.atheism. This is surprising as 'bobby' is not necessarily a religious word, yet appears to have a large weight and impact in the model. Furthermore, we can also see that both 'athiests' and 'atheism', 'files' and 'file', as well as 'christian' and 'christians' are in the top 5 largest weights for talk.religion.misc, comp.graphics, and talk.religion.misc respectively. So, there is no regular expression being done for this data set with CountVectorization. Although these features are not surprising as they are signifigant to their topic, they could be combined into a single representative feature.\n",
    "\n",
    "In the bi-gram table, 'cheers kent' is in the top 5 largest weights for both alt.atheism and talk.religion.misc categories. Although both categories have religion as a common topic, the phrase \"cheers kent\" is not necessarly a common religious phrase, making this the most surprising feature in the tables. Additionally, many of the bi-grams per category are not very unique or significant in relation to the topic. For instance, 'are you' and 'it was' do not provide any indication of the categories to which they belong, yet these features have large weights. Although this isn't very surprising given how common these combinations of words are, other features would be more useful for topic category prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVWhSJHHFsxu"
   },
   "source": [
    "### Part 5:\n",
    "\n",
    "Try to improve the logistic regression classifier by passing a custom preprocessor to CountVectorizer. The preprocessing function runs on the raw text, before it is split into words by the tokenizer. Your preprocessor should try to normalize the input in various ways to improve generalization. For example, try lowercasing everything, replacing sequences of numbers with a single token, removing various other non-letter characters, and shortening long words. If you're not already familiar with regular expressions for manipulating strings, see https://docs.python.org/2/library/re.html, and re.sub() in particular. With your new preprocessor, how much did you reduce the size of the dictionary?\n",
    "\n",
    "For reference, I was able to improve dev F1 by 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/erinwerner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download stopwords for tokenization\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_preprocessor(s):\n",
    "    \"\"\" empty_preprocessor - Takes a single training document as an input, makes no changes to it, and returns the\n",
    "            same string.\n",
    "    # param: s - string input that represents a training document\n",
    "    # return: s - string output that represents a unmanipulated training document\n",
    "    \"\"\"\n",
    "    \n",
    "    #returns the original string\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_preprocessor(s):\n",
    "    \"\"\" better_preprocessor - Takes a single training document as an input, performs multiple different manipulations\n",
    "            in order to normalize the input and improve its generalization.\n",
    "    # param: s - string input that represents a training document\n",
    "    # return: s - string output that represents a changed training document\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize a word stemmer and a set of stop words for tokenization\n",
    "    ps = nltk.stem.porter.PorterStemmer()\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    #lower the case of all words and remove special symbols\n",
    "    new_str = s.lower()\n",
    "    new_str = re.sub(r'[()?<>_,.\":!;]', ' ', new_str)\n",
    "    new_str = re.sub(r'!\"#$%&()+,-./:;<=>@?\\^_`{|}~', ' ', new_str)\n",
    "    new_str = new_str.strip()\n",
    "    new_str = new_str.replace('\\n', ' ')\n",
    "    new_str = new_str.replace('@', ' ')\n",
    "    new_str = new_str.replace('*', ' ')\n",
    "    new_str = new_str.replace('-', '')\n",
    "    new_str = new_str.replace('}', '')\n",
    "    new_str = new_str.replace('/', ' ')\n",
    "    \n",
    "    #replace numbers with a special symbol (*)\n",
    "    new_str = re.sub(r'\\d+', ' * ', new_str)\n",
    "\n",
    "    #tokenize and stem the words\n",
    "    tokens = nltk.word_tokenize(new_str)\n",
    "    result = [i for i in tokens if not i in stop_words]\n",
    "    temp = [ps.stem(token) for token in result]\n",
    "\n",
    "    #join the tokenized/stemmed words back into a single string output\n",
    "    separator = ' '\n",
    "    new_str = separator.join(temp)\n",
    "    new_str = re.sub(\"\\s\\s+\" , \" \", new_str)\n",
    "\n",
    "    #return the manipulated string\n",
    "    s = new_str\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erin_CV_LR(my_train_data, my_dev_data, orig=True):\n",
    "    \"\"\" erin_CV_LR - Fits a countVectorizer to the given training data and then fits that to a logistic regression\n",
    "                model, printing the size of the dictionary and the F1 score for each.\n",
    "    # param: my_train_data - the training data set in which to fit the countVectorizer and the logistic regression\n",
    "                model; the training data set can be the original or the preprocessed data\n",
    "    # param: orig (default = True) - boolean parameter to indicate whether the training data that is input into the\n",
    "                function is the original training data or the preprocessed training data\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #sets countVectorizr and fits the original/preprocessed training and dev data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(my_train_data)\n",
    "    X_dev = vectorizer.transform(my_dev_data)\n",
    "    \n",
    "    #indicates what type of training data is used for logistic regression  \n",
    "    if orig == True:\n",
    "        print('Original Training Data Results: \\n')\n",
    "    else:\n",
    "        print('Preprocessed Training Data Results: \\n')\n",
    "\n",
    "    #prints size of the dictionary\n",
    "    print('Size of Vocabulary: ', X.shape[1])\n",
    "\n",
    "    #trains the logistic regression model\n",
    "    LRclf = LogisticRegression(penalty = 'l2', C = 0.1, solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "\n",
    "    #evaluate on the dev data\n",
    "    LRy_pred = LRclf.predict(X_dev)\n",
    "\n",
    "    #get array of F1-scores\n",
    "    print('F1 Score: ', metrics.f1_score(dev_labels, LRy_pred, average='weighted'), '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7gS3cGpFsxv"
   },
   "outputs": [],
   "source": [
    "def P5():\n",
    "    \"\"\" P5 - Trains a logistic regression model for two different training data set, one that is\n",
    "            unchanged and the other that has been preprocessed. The size of the vocabulary and the F1 scores are then\n",
    "            displayed to compare results.\n",
    "    # param: None\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize parameters\n",
    "    old_train_data = []\n",
    "    new_train_data = []\n",
    "    old_dev_data = []\n",
    "    new_dev_data = []\n",
    "\n",
    "    #iterate through each document in the training data\n",
    "    for i in range(0,len(train_data)):\n",
    "        #make a copy of the training data\n",
    "        old_str = empty_preprocessor(train_data[i])\n",
    "        old_train_data.append(old_str)\n",
    "\n",
    "        #preprocess the training data and create a new training data set\n",
    "        new_str = better_preprocessor(train_data[i])\n",
    "        new_train_data.append(new_str)\n",
    "\n",
    "    #iterate through each document in the training data\n",
    "    for j in range(0,len(dev_data)):\n",
    "        #make a copy of the dev data\n",
    "        old_str = empty_preprocessor(dev_data[j])\n",
    "        old_dev_data.append(old_str)\n",
    "\n",
    "        #preprocess the dev data and create a new dev data set\n",
    "        new_str = better_preprocessor(dev_data[j])\n",
    "        new_dev_data.append(new_str)\n",
    "\n",
    "    #fit the original training and dev data\n",
    "    erin_CV_LR(old_train_data, old_dev_data, orig=True)\n",
    "\n",
    "    #fit the preprocessed training and dev data\n",
    "    erin_CV_LR(new_train_data, new_dev_data, orig=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Data Results: \n",
      "\n",
      "Size of Vocabulary:  26879\n",
      "F1 Score:  0.6971054614079846 \n",
      "\n",
      "Preprocessed Training Data Results: \n",
      "\n",
      "Size of Vocabulary:  18032\n",
      "F1 Score:  0.7170702094502918 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n",
    "* With your new preprocessor, how much did you reduce the size of the dictionary?\n",
    "\n",
    "With my new preprocessor, I was able to reduce the size of the dictionary by about 8,800 words. I was also able to improve the F1 score by 2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uy-WITbNFsxw"
   },
   "source": [
    "### Part 6:\n",
    "\n",
    "The idea of regularization is to avoid learning very large weights (which are likely to fit the training data, but not generalize well) by adding a penalty to the total size of the learned weights. That is, logistic regression seeks the set of weights that minimizes errors in the training data AND has a small size. The default regularization, L2, computes this size as the sum of the squared weights (see P3, above). L1 regularization computes this size as the sum of the absolute values of the weights. The result is that whereas L2 regularization makes all the weights relatively small, L1 regularization drives lots of the weights to 0, effectively removing unimportant features.\n",
    "\n",
    "Train a logistic regression model using a \"l1\" penalty. Output the number of learned weights that are not equal to zero. How does this compare to the number of non-zero weights you get with \"l2\"? Now, reduce the size of the vocabulary by keeping only those features that have at least one non-zero weight and retrain a model using \"l2\".\n",
    "\n",
    "Make a plot showing accuracy of the re-trained model vs. the vocabulary size you get when pruning unused features by adjusting the C parameter.\n",
    "\n",
    "Note: The gradient descent code that trains the logistic regression model sometimes has trouble converging with extreme settings of the C parameter. Relax the convergence criteria by setting tol=.015 (the default is .0001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erin_l2_baseline(Cval):\n",
    "    \"\"\" erin_l2_baseline - Trains a count vectorizer and a logistic regression model, then gets the count of the\n",
    "                nonzero weights for the model.\n",
    "    # param: Cval - different input C values for the regularization value in the logistic regression model\n",
    "    # return: l2_nonzero_weight_count - the count of the nonzero weights in the logistic regression model for the\n",
    "                given C value input\n",
    "    \"\"\"\n",
    "\n",
    "    print('L2 Baseline Model: \\n')\n",
    "\n",
    "    #sets countVectorizr and fits the training data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "\n",
    "    #trains the logistic regression model using l2 regularization penalty\n",
    "    LRclf = LogisticRegression(penalty = 'l2', C = Cval, solver='lbfgs', multi_class='auto', max_iter=3000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "\n",
    "    #initialize variables\n",
    "    l2_nonzero_weight_count = 0\n",
    "    l2_total_count = 0\n",
    "\n",
    "    #iterate through the weights for each category\n",
    "    for i in [0,1,2,3]:\n",
    "\n",
    "        #gets the coefficients for the given label\n",
    "        coefs = LRclf.coef_[i]\n",
    "\n",
    "        #iterate through the individual weights\n",
    "        for j in coefs:\n",
    "            #increment total count\n",
    "            l2_total_count += 1\n",
    "\n",
    "            #increment the count for nonzero weights accordingly\n",
    "            if j > 0.0:\n",
    "                l2_nonzero_weight_count += 1\n",
    "\n",
    "    #print the number of nonzero weights\n",
    "    print('\\tL2 - Learned Weights NOT Equal to Zero: ', l2_nonzero_weight_count)\n",
    "    print('\\tL2 - Percent of Nonzero Weights: ', l2_nonzero_weight_count/l2_total_count)\n",
    "    \n",
    "    return(l2_nonzero_weight_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erin_l1_model(Cval):\n",
    "    \"\"\" erin_l1_model - Trains a count vectorizer and a logistic regression model with l1 penalty. Then, get the  \n",
    "                count of the nonzero weights for the model and a new vocabulary of just the features with at\n",
    "                least one nonzero weight value.\n",
    "    # param: Cval - different input C values for the regularization value in the logistic regression model\n",
    "    # return: l1_nonzero_weight_count - the count of the nonzero weights in the logistic regression model for the\n",
    "                given C value input\n",
    "    # return: new_vocab - the new vocabulary consisting of just word features with nonzeros weights\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\nL1 Model: \\n')\n",
    "\n",
    "    #sets countVectorizr and fits the training data\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "\n",
    "    #trains the logistic regression model using l1 regularization penalty\n",
    "    LRclf = LogisticRegression(penalty = 'l1', C = Cval, solver='liblinear', multi_class='auto', max_iter=5000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "    \n",
    "    #initialize variables\n",
    "    l1_nonzero_weight_count = 0\n",
    "    l1_total_count = 0\n",
    "    new_vocab = []\n",
    "\n",
    "    #iterate through the weights for each category\n",
    "    for i in [0,1,2,3]:\n",
    "        #gets the coefficients for the given label\n",
    "        coefs = LRclf.coef_[i]\n",
    "        feature_count = -1\n",
    "\n",
    "        #iterate through the individual weights\n",
    "        for j in coefs:\n",
    "            #set iterable count to get feature associated with weight\n",
    "            feature_count += 1\n",
    "\n",
    "            #increment total count\n",
    "            l1_total_count += 1\n",
    "\n",
    "            #increment the count for nonzero weights accordingly\n",
    "            if j > 0.0:\n",
    "                #create a new vocab for words with nonzero weights\n",
    "                feature_w_weight = vectorizer.get_feature_names()[feature_count]\n",
    "                new_vocab.append(feature_w_weight)\n",
    "\n",
    "                #increment the nonzero weight count\n",
    "                l1_nonzero_weight_count += 1\n",
    "\n",
    "    #get unique words from the list\n",
    "    new_vocab = list(set(new_vocab))\n",
    "\n",
    "    #print the number of nonzero weights\n",
    "    print('\\tL1 - Learned Weights NOT Equal to Zero: ', l1_nonzero_weight_count)\n",
    "    print('\\tL1 - Percent of Nonzero Weights: ', l1_nonzero_weight_count/l1_total_count)\n",
    "    \n",
    "    return(l1_nonzero_weight_count, new_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erin_l2_reduced_vocab(i, my_vocab):\n",
    "    \"\"\" erin_l2_reduced_vocab - Trains a count vectorizer and a logistic regression model with l2 penalty. Then, \n",
    "            gets the accuracy for the given C value and reduced vocabulary.\n",
    "    # param: i - different input C values for the regularization value in the logistic regression model\n",
    "    # param: my_vocab - the new reduced vocabulary that consists of features with nonzero weights that was\n",
    "                produced from the logistic regression model with l1 penalty\n",
    "    # return: my_acc - the accuracy of the model for the given C value and the reduced vocabulary \n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\nL2 Model w/ Reduced Vocabulary: \\n')\n",
    "\n",
    "    #sets countVectorizr and fits the training data\n",
    "    if len(my_vocab) > 0:\n",
    "        vectorizer = CountVectorizer(vocabulary=my_vocab)\n",
    "    else:\n",
    "        vectorizer = CountVectorizer()\n",
    "        \n",
    "    #fit the traing and dev data to the model\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "    X_dev = vectorizer.transform(dev_data)\n",
    "\n",
    "    #trains the logistic regression model using l2 regularization penalty\n",
    "    LRclf = LogisticRegression(penalty = 'l2', C = i, solver='lbfgs', multi_class='auto', tol=.015, \n",
    "                               max_iter=3000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "\n",
    "    #evaluate on the dev data\n",
    "    LRy_pred = LRclf.predict(X_dev)\n",
    "    \n",
    "    my_acc = metrics.f1_score(dev_labels, LRy_pred, average='weighted')\n",
    "\n",
    "    print('\\tAccuracy: ', my_acc, '\\n')\n",
    "    \n",
    "    return(my_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6ho31SrFsxx"
   },
   "outputs": [],
   "source": [
    "def P6():\n",
    "    \"\"\" P6 - Trains multiple logistic regression models, with different penalties and vocabularies. Then, produces\n",
    "                a plot that shows the accuracy of the re-trained model vs. the vocabulary size you get when \n",
    "                pruning unused features by adjusting the C parameter\n",
    "    # param: None\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep this random seed here to make comparison easier.\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    #initialize variables\n",
    "    my_accuracies = []\n",
    "    my_vocab_sizes = []\n",
    "\n",
    "    #iterate through different values of C\n",
    "    C_values = [0.001,0.01,0.1,1]\n",
    "    for i in C_values:\n",
    "\n",
    "        print('For C = ', i, '\\n')\n",
    "\n",
    "        #get the baseline number of nonzero weights for the logistic regerssion model with l2 penalty\n",
    "        l2_count = erin_l2_baseline(i)\n",
    "\n",
    "        #get the number of nonzero weights and the new reduced vocabulary from the logistic regression model\n",
    "            #with l1 penalty\n",
    "        l1_count, my_vocab = erin_l1_model(i)\n",
    "        my_vocab_sizes.append(len(my_vocab))\n",
    "\n",
    "        #print the different in the nonzero weight counts\n",
    "        print('\\nDifference between L2 and L1 Nonzero Weight Count: ', l2_count - l1_count, '\\n')\n",
    "\n",
    "        #get the accuracy of the logistic regression model with l2 penalty and the reduced vocabulary\n",
    "        my_acc = erin_l2_reduced_vocab(i, my_vocab)\n",
    "        my_accuracies.append(my_acc)\n",
    "\n",
    "    #plot the accuracy of the re-trained model vs. the vocabulary size you get when \n",
    "        #pruning unused features by adjusting the C parameter\n",
    "    plt.figure(figsize=[10,8])\n",
    "    plt.plot(my_vocab_sizes, my_accuracies)\n",
    "    plt.grid(axis='y')\n",
    "    plt.xlabel('Vocabulary Size',fontsize=15)\n",
    "    plt.ylabel('Accuracy',fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title('Accuracy vs. Vocabulary Size per C Values (0.001 - 1)',fontsize=15)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  0.001 \n",
      "\n",
      "L2 Baseline Model: \n",
      "\n",
      "\tL2 - Learned Weights NOT Equal to Zero:  35960\n",
      "\tL2 - Percent of Nonzero Weights:  0.33446184753897096\n",
      "\n",
      "L1 Model: \n",
      "\n",
      "\tL1 - Learned Weights NOT Equal to Zero:  0\n",
      "\tL1 - Percent of Nonzero Weights:  0.0\n",
      "\n",
      "Difference between L2 and L1 Nonzero Weight Count:  35960 \n",
      "\n",
      "\n",
      "L2 Model w/ Reduced Vocabulary: \n",
      "\n",
      "\tAccuracy:  0.5328493709625631 \n",
      "\n",
      "For C =  0.01 \n",
      "\n",
      "L2 Baseline Model: \n",
      "\n",
      "\tL2 - Learned Weights NOT Equal to Zero:  40801\n",
      "\tL2 - Percent of Nonzero Weights:  0.3794877041556606\n",
      "\n",
      "L1 Model: \n",
      "\n",
      "\tL1 - Learned Weights NOT Equal to Zero:  14\n",
      "\tL1 - Percent of Nonzero Weights:  0.00013021317757357044\n",
      "\n",
      "Difference between L2 and L1 Nonzero Weight Count:  40787 \n",
      "\n",
      "\n",
      "L2 Model w/ Reduced Vocabulary: \n",
      "\n",
      "\tAccuracy:  0.4339132050115384 \n",
      "\n",
      "For C =  0.1 \n",
      "\n",
      "L2 Baseline Model: \n",
      "\n",
      "\tL2 - Learned Weights NOT Equal to Zero:  30968\n",
      "\tL2 - Percent of Nonzero Weights:  0.28803154879273785\n",
      "\n",
      "L1 Model: \n",
      "\n",
      "\tL1 - Learned Weights NOT Equal to Zero:  207\n",
      "\tL1 - Percent of Nonzero Weights:  0.0019252948398377917\n",
      "\n",
      "Difference between L2 and L1 Nonzero Weight Count:  30761 \n",
      "\n",
      "\n",
      "L2 Model w/ Reduced Vocabulary: \n",
      "\n",
      "\tAccuracy:  0.6688087552782397 \n",
      "\n",
      "For C =  1 \n",
      "\n",
      "L2 Baseline Model: \n",
      "\n",
      "\tL2 - Learned Weights NOT Equal to Zero:  31173\n",
      "\tL2 - Percent of Nonzero Weights:  0.2899382417500651\n",
      "\n",
      "L1 Model: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tL1 - Learned Weights NOT Equal to Zero:  869\n",
      "\tL1 - Percent of Nonzero Weights:  0.008082517950816622\n",
      "\n",
      "Difference between L2 and L1 Nonzero Weight Count:  30304 \n",
      "\n",
      "\n",
      "L2 Model w/ Reduced Vocabulary: \n",
      "\n",
      "\tAccuracy:  0.6611244548313229 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "P6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmrHf8AMFsxz"
   },
   "source": [
    "### Part 7:\n",
    "\n",
    "Use the TfidfVectorizer -- how is this different from the CountVectorizer? Train a logistic regression model with C=100.\n",
    "\n",
    "Make predictions on the dev data and show the top 3 documents where the ratio R is largest, where R is:\n",
    "\n",
    "maximum predicted probability / predicted probability of the correct label\n",
    "\n",
    "What kinds of mistakes is the model making? Suggest a way to address one particular issue that you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vwU_9t2Fsx0"
   },
   "outputs": [],
   "source": [
    "def P7():\n",
    "    \"\"\" P7 - Uses the TfidfVectorizer function then trains a logistic regression model with C = 100. Then, makes \n",
    "                predictions on the dev data and calculates each document's R ratio, which is the maximum predicted \n",
    "                probability divided by the predicted probability of the correct label. The three documents with the\n",
    "                largest R ratio are then displayed.\n",
    "    # param: None\n",
    "    # return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #sets TfidfVectorizer and fits the training and dev data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(train_data)\n",
    "    X_dev = vectorizer.transform(dev_data)\n",
    "    \n",
    "    #train and fit the LR model\n",
    "    LRclf = LogisticRegression(penalty = 'l2', C = 100, solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "    LRclf.fit(X, train_labels)\n",
    "    \n",
    "    #evaluate on the dev data\n",
    "    LRy_pred = LRclf.predict(X_dev)\n",
    "    \n",
    "    #initialize variables\n",
    "    all_R = []\n",
    "\n",
    "    #iterate through each document in the dev data\n",
    "    for i in range(0, len(LRclf.predict_proba(X_dev))):\n",
    "        #get predicted probabilities\n",
    "        my_probs = LRclf.predict_proba(X_dev)[i]\n",
    "\n",
    "        #get max probability and the actual probability\n",
    "        my_max = max(my_probs)\n",
    "        my_actual = my_probs[dev_labels[i]]\n",
    "\n",
    "        #compute R and append to list\n",
    "        temp_R = my_max/my_actual\n",
    "        all_R.append(temp_R)\n",
    "     \n",
    "    #iterate through the top 3\n",
    "    for j in [1,2,3]:\n",
    "        #get the index and the value for the largest R's\n",
    "        large_R_index = np.argmax(all_R)\n",
    "        large_R_value = all_R[large_R_index]\n",
    "\n",
    "        #reset for next iteration\n",
    "        all_R[large_R_index] = -1\n",
    "\n",
    "        #get the message and the actual/predicted labels for the doc with large R\n",
    "        R_message = dev_data[large_R_index]\n",
    "        R_actual_label = dev_labels[large_R_index]\n",
    "        R_predicted_label = LRy_pred[large_R_index]\n",
    "\n",
    "        #map the actual label to its category\n",
    "        if R_actual_label == 0:\n",
    "            lab_type1 = 'alt.atheism'\n",
    "        elif R_actual_label == 1:\n",
    "            lab_type1 = 'comp.graphics'\n",
    "        elif R_actual_label == 2:\n",
    "            lab_type1 = 'sci.space'\n",
    "        else:\n",
    "            lab_type1 = 'talk.religion.misc'\n",
    "\n",
    "        #map the predicted label to its category\n",
    "        if R_predicted_label == 0:\n",
    "            lab_type2 = 'alt.atheism'\n",
    "        elif R_predicted_label == 1:\n",
    "            lab_type2 = 'comp.graphics'\n",
    "        elif R_predicted_label == 2:\n",
    "            lab_type2 = 'sci.space'\n",
    "        else:\n",
    "            lab_type2 = 'talk.religion.misc'\n",
    "\n",
    "        #print the messages and their labels\n",
    "        print('Document with #', j, ' largest ratio R: ', R_message )\n",
    "        print('\\nActual Label: ', R_actual_label, ' & Actual Label Category: ', lab_type1)\n",
    "        print('\\nPredicted Label: ', R_predicted_label, ' & Actual Label Category: ', lab_type2)\n",
    "        print('\\nR: ', large_R_value)\n",
    "        print('\\n_________________________________________________________________________________________\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with # 1  largest ratio R:  Can anyone provide me a ftp site where I can obtain a online version\n",
      "of the Book of Mormon. Please email the internet address if possible.\n",
      "\n",
      "Actual Label:  3  & Actual Label Category:  talk.religion.misc\n",
      "\n",
      "Predicted Label:  1  & Actual Label Category:  comp.graphics\n",
      "\n",
      "R:  736.1715870512901\n",
      "\n",
      "_________________________________________________________________________________________\n",
      "\n",
      "Document with # 2  largest ratio R:  I am pleased to announce that a *revised version* of _The Easy-to-Read Book\n",
      "of Mormon_ (former title: _Mormon's Book_) by Lynn Matthews Anderson is now\n",
      "available through anonymous ftp (see information below). In addition to the\n",
      "change in title, the revised ETR BOM has been shortened by several pages\n",
      "(eliminating many extraneous \"that's\" and \"of's\"), and many (minor) errors\n",
      "have been corrected. This release includes a simplified Joseph Smith Story,\n",
      "testimonies of the three and eight witnesses, and a \"Words-to-Know\"\n",
      "glossary.\n",
      "\n",
      "As with the previous announcement, readers are reminded that this is a\n",
      "not-for-profit endeavor. This is a copyrighted work, but people are welcome\n",
      "to make *verbatim* copies for personal use. People can recuperate the\n",
      "actual costs of printing (paper, copy center charges), but may not charge\n",
      "anything for their time in making copies, or in any way realize a profit\n",
      "from the use of this book. See the permissions notice in the book itself\n",
      "for the precise terms.\n",
      "\n",
      "Negotiations are currently underway with a Mormon publisher vis-a-vis the\n",
      "printing and distribution of bound books. (Sorry, I'm out of the wire-bound\n",
      "\"first editions.\") I will make another announcement about the availability\n",
      "of printed copies once everything has been worked out.\n",
      "\n",
      "FTP information: connect via anonymous ftp to carnot.itc.cmu.edu, then \"cd\n",
      "pub\" (you won't see anything at all until you do).\n",
      "\n",
      "\"The Easy-to-Read Book of Mormon\" is currently available in postscript and\n",
      "RTF (rich text format). (ASCII, LaTeX, and other versions can be made\n",
      "available; contact dba@andrew.cmu.edu for details.) You should be able to\n",
      "print the postscript file on any postscript printer (such as an Apple\n",
      "Laserwriter); let dba know if you have any difficulties. (The postscript in\n",
      "the last release had problems on some printers; this time it should work\n",
      "better.) RTF is a standard document interchange format that can be read in\n",
      "by a number of word processors, including Microsoft Word for both the\n",
      "Macintosh and Windows. If you don't have a postscript printer, you may be\n",
      "able to use the RTF file to print out a copy of the book.\n",
      "\n",
      "-r--r--r--  1 dba                   1984742 Apr 27 13:12 etrbom.ps\n",
      "-r--r--r--  1 dba                   1209071 Apr 27 13:13 etrbom.rtf\n",
      "\n",
      "For more information about how this project came about, please refer to my\n",
      "article in the current issue of _Sunstone_, entitled \"Delighting in\n",
      "Plainness: Issues Surrounding a Simple Modern English Book of Mormon.\"\n",
      "\n",
      "Send all inquiries and comments to:\n",
      "\n",
      "    Lynn Matthews Anderson\n",
      "    5806 Hampton Street\n",
      "    Pittsburgh, PA 15206\n",
      "\n",
      "Actual Label:  3  & Actual Label Category:  talk.religion.misc\n",
      "\n",
      "Predicted Label:  1  & Actual Label Category:  comp.graphics\n",
      "\n",
      "R:  503.38078919065646\n",
      "\n",
      "_________________________________________________________________________________________\n",
      "\n",
      "Document with # 3  largest ratio R:  Why is the NT tossed out as info on Jesus.  I realize it is normally tossed\n",
      "out because it contains miracles, but what are the other reasons?\n",
      "\n",
      "MAC\n",
      "--\n",
      "****************************************************************\n",
      "                                                    Michael A. Cobb\n",
      " \"...and I won't raise taxes on the middle     University of Illinois\n",
      "    class to pay for my programs.\"                 Champaign-Urbana\n",
      "          -Bill Clinton 3rd Debate             cobb@alexia.lis.uiuc.edu\n",
      "\n",
      "Actual Label:  3  & Actual Label Category:  talk.religion.misc\n",
      "\n",
      "Predicted Label:  0  & Actual Label Category:  alt.atheism\n",
      "\n",
      "R:  206.74783948759253\n",
      "\n",
      "_________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZmIPwExFsx1"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "* How is TfidfVectorizer different from the CountVectorizer? \n",
    "\n",
    "TfidfVectorizer is different from CountVectorizer. CountVectorizer implements both tokenization and occurrence counting in a single class. However, as we have seen in previous Parts, some words will be very present (e.g. “the”, “a”, “is” in English) despite carrying very little meaningful information about the actual contents of the document. By just relying on count, those very frequent terms then shadow the frequencies of rarer yet more interesting terms. So, in order to re-weight the count features into values suitable for usage by a classifier, it is very common to use the tf–idf transform. The tfidf transformation calculates the term frequency, the number of times a term occurs in a given document, then  multiplies it with the idf component. The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.\n",
    "\n",
    "* What kinds of mistakes is the model making? Suggest a way to address one particular issue that you see.\n",
    "\n",
    "There are a few mistakes that the model makes. \n",
    "\n",
    "The IDF component of TF*IDF can harm the classification accuracy in some cases. The inverse document frequency of a certain distinguishing word will be very low if it occurs frequently in a large training data set, across many documents. That feature would then get a very small TFIDF, which is the weight of the feature used by the classifier. This is an example where TFIDF may reduce the classification accuracy. So if there are more instances in one class, the good word features of the frequent class risk having lower IDF, thus their best features will have a lower weight due to class imbalance. \n",
    "\n",
    "It is then possible that words that occur frequently in one class can also appear frequently in a different class. This would increase the IDF score, which would then lower the weight of that feature for both classes. If those two classes were imbalanced in size, the bigger class will have other distinguishable features to help classify it. So, if one class that is very big shares a distinguishing feature with a class that is smaller, the smaller class will be harder to classify due to the tfidf weighting scheme. \n",
    "\n",
    "In this context, it seems as though the model has trouble distinguishing Class 3, the 'talk.religion.misc' category. Each of the documents with the top three highest R-scores should be labeled as Class 3. Yet, they are predicted to be something else. This could be because the 'misc' portion of the category makes it a very broad category and so the features are not representative enough to distinuish it from a different category. It could also be because Class 3 shares a religious subject with Class 0, 'alt.atheism'. \n",
    "\n",
    "As a result, a potential way to address this issue it to implement random oversampling for our training data. This would consist of determining the classes that have fewer documents in them. Then, additional copies of documents in that category would be added to the overall data set. This is essentially resampling with replacement. The method would help to normalize class imbalances and reduce the problems mentioned above. Another potential solution would be to preprocess and tokenize the data. These methods would normalize the input in various ways to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmsDxtzoFsx1"
   },
   "source": [
    "### Part 8 EXTRA CREDIT:\n",
    "\n",
    "Try implementing one of your ideas based on your error analysis. Use logistic regression as your underlying model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my error analysis, I will apply resampling and preprocesing/tokenization to my data. Then, I will use the TfidfVectorizer function in order to transform my text data for my logistic regression model.\n",
    "\n",
    "First, we will establish a basline model. This consists of unmanipulated data and no extra tuning of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7680092163691469\n"
     ]
    }
   ],
   "source": [
    "#use the Pipeline to train a TfidfVectorizer and LogisticRegression model of the training and dev data \n",
    "pipeline = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "                     ('lr',LogisticRegression(penalty = 'l2', C = 100, solver='lbfgs', \n",
    "                                              multi_class='auto', max_iter=1000))])\n",
    "pipeline.fit(train_data,train_labels)\n",
    "pipe_pred = pipeline.predict(dev_data)\n",
    "\n",
    "#print the F1 score for the model to serve as a baseline\n",
    "print(metrics.f1_score(dev_labels, pipe_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline F1 score will be 0.76.\n",
    "\n",
    "Next, we will apply the reampling method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the distribution of documents between the four topic categories\n",
    "plt.figure(figsize=[10,8])\n",
    "bins = np.arange(5) - 0.5\n",
    "plt.hist(train_labels, bins)\n",
    "plt.xlim(-1, 3.5)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Category',fontsize=15)\n",
    "plt.ylabel('Frequency',fontsize=15)\n",
    "plt.xticks(range(5), fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title('Category Distribution',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Category 0 and Category 3 are substantially smaller than Category 1 and Category 2. So, we will add more samples from Category 3 and 0, but more from 3 than 0. This will be done to help normalze the class imbalances and allow for greater category representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "cat0 = []\n",
    "lab0 = []\n",
    "cat1 = []\n",
    "lab1 = []\n",
    "cat2 = []\n",
    "lab2 = []\n",
    "cat3 = []\n",
    "lab3 = []\n",
    "\n",
    "#iterate through the training data\n",
    "for i in range(0,len(train_data)):\n",
    "    #get the docuemnt and labels\n",
    "    my_doc = train_data[i]\n",
    "    my_lab = train_labels[i]\n",
    "    \n",
    "    #separate the training data into respective categories\n",
    "    if my_lab == 0:\n",
    "        cat0.append(my_doc)\n",
    "        lab0.append(0)\n",
    "    elif my_lab == 1:\n",
    "        cat1.append(my_doc)\n",
    "        lab1.append(1)\n",
    "    elif my_lab == 2:\n",
    "        cat2.append(my_doc)\n",
    "        lab2.append(2)\n",
    "    else:\n",
    "        cat3.append(my_doc)\n",
    "        lab3.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle add the data to make the oversampling truely random\n",
    "np.random.shuffle(cat0)\n",
    "np.random.shuffle(cat1)\n",
    "np.random.shuffle(cat2)\n",
    "np.random.shuffle(cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new copies of the training data\n",
    "td_copy = train_data.copy()\n",
    "tl_copy = train_labels.copy().tolist()\n",
    "\n",
    "#add additional documents from the smaller categories to the training data\n",
    "for i in range(0,225):\n",
    "    td_copy.append(cat3[i])\n",
    "    tl_copy.append(lab3[i])\n",
    "    \n",
    "    #add fewer documents from Category 0\n",
    "    if i <= 75:\n",
    "        td_copy.append(cat0[i])\n",
    "        tl_copy.append(lab0[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the new distribution of documents between the four topic categories\n",
    "plt.figure(figsize=[10,8])\n",
    "bins = np.arange(5) - 0.5\n",
    "plt.hist(tl_copy, bins)\n",
    "plt.xlim(-1, 3.5)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Category',fontsize=15)\n",
    "plt.ylabel('Frequency',fontsize=15)\n",
    "plt.xticks(range(5), fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title('Category Distribution',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is now a more even distribution of documents within each category. Although Category 3 now has the most documents in the data set, the classifer had the most difficulty with this topic so this will help to improve its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7743384137031204\n"
     ]
    }
   ],
   "source": [
    "#use the Pipeline to form the TfidfVectorizer and LogisticRegression functions\n",
    "pipeline = Pipeline([('tfidf',TfidfVectorizer(ngram_range=(1, 2))),\n",
    "                     ('lr',LogisticRegression(penalty = 'l2', C = 100, solver='lbfgs', \n",
    "                                              multi_class='auto', max_iter=1000))])\n",
    "\n",
    "#fit the resampled data to the pipeline model\n",
    "pipeline.fit(td_copy,tl_copy)\n",
    "\n",
    "#get the predictions for the dev data\n",
    "pipe_pred = pipeline.predict(dev_data)\n",
    "\n",
    "#print the F1 score, for comparison\n",
    "print(metrics.f1_score(dev_labels, pipe_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resampling (random oversampling) method did improve the F1-score to 0.77. This helped to reduce the class imbalances. Although it was only a small improvement, the resampling was very basic as it merely added more samles for the two topic categories that had fewer documents in the training data. A more extensive resampling could be applied in the future with functions in other libraries. Nonetheless, resampling helped to improve the model, using the TfidfVectorizer and LogisticRegression.\n",
    "\n",
    "Last, we will try to tokenize and preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize & Preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erin_preprocessor(s):\n",
    "    \"\"\" erin_preprocessor - Takes a single training document as an input, performs multiple different manipulations\n",
    "            in order to normalize the input and improve its generalization.\n",
    "    # param: s - string input that represents a training document\n",
    "    # return: s - string output that represents a changed training document\n",
    "    \"\"\"\n",
    "    \n",
    "    #lower the case of all words and remove special symbols\n",
    "    new_str = s.lower()\n",
    "    new_str = re.sub(r'[()?<>_,.\":!;]', ' ', new_str)\n",
    "    new_str = re.sub(r'!\"#$%&()+,-./:;<=>@?\\^_`{|}~', ' ', new_str)\n",
    "    new_str = new_str.strip()\n",
    "    new_str = new_str.replace('\\n', ' ')\n",
    "    new_str = new_str.replace('@', ' ')\n",
    "    new_str = new_str.replace('*', ' ')\n",
    "    new_str = new_str.replace('-', '')\n",
    "    new_str = new_str.replace('%', '')\n",
    "    new_str = new_str.replace('|', '')\n",
    "    new_str = new_str.replace('}', '')\n",
    "    new_str = new_str.replace('/', ' ')\n",
    "    \n",
    "    #replace numbers with a special symbol (*)\n",
    "    new_str = re.sub(r'\\d+', ' * ', new_str)\n",
    "    \n",
    "    s = new_str\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" tokenize - Takes a single training document as an input, performs tokenization and stemming on the string,\n",
    "            then returns the list of manipulated words.\n",
    "    # param: text - string input that represents a training document\n",
    "    # return: stems - list output that represents a changed training document\n",
    "    \"\"\"\n",
    "    \n",
    "    #tokeninze the document\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #initialize variables\n",
    "    stems = []\n",
    "    \n",
    "    #iterate through each token\n",
    "    for item in tokens:\n",
    "        \n",
    "        #stem the token\n",
    "        stems.append(nltk.stem.porter.PorterStemmer().stem(item))\n",
    "        \n",
    "    #return the list of stemmed tokens\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7618028160113318\n"
     ]
    }
   ],
   "source": [
    "#use the Pipeline to form the TfidfVectorizer and LogisticRegression functions\n",
    "pipeline = Pipeline([('tfidf',TfidfVectorizer(tokenizer=tokenize, \n",
    "                        preprocessor=erin_preprocessor,\n",
    "                        min_df=5, max_df=0.8,\n",
    "                        ngram_range=(1, 2))),\n",
    "                     ('lr',LogisticRegression(penalty = 'l2', C = 100, solver='lbfgs', \n",
    "                                              multi_class='auto', max_iter=1000))])\n",
    "\n",
    "#fit the original data to the pipeline model with tokenization/preprocessing\n",
    "pipeline.fit(train_data,train_labels)\n",
    "\n",
    "#get the predictions for the dev data\n",
    "pipe_pred = pipeline.predict(dev_data)\n",
    "\n",
    "#print the F1 score, for comparison\n",
    "print(metrics.f1_score(dev_labels, pipe_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization and preprocessing did not necessarily improve the F1 score, but it did, at least, achieve the same score F1 score as the basline model with a score of 0.76. These techniques aim to improve the generalization of the vocabulary, yet its seems that resampling was more effective in improveing the F1 score for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "firstname_lastname_p2.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/MIDS-W207/Master/blob/master/Projects/firstname_lastname_p2.ipynb",
     "timestamp": 1559779272103
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
